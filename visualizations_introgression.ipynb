{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import LogNorm, Normalize, CenteredNorm, SymLogNorm\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress, t, gaussian_kde, mannwhitneyu, hmean, combine_pvalues, fisher_exact, ttest_1samp\n",
    "from pybedtools import BedTool, helpers\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "helpers.set_tempdir(\n",
    "        '/home/jupyter/workspaces/neanderthalintrogressionlandscapeinafricanamericans/introgression_african_americans')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Plot admixutre proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ibdmix_results(filename):\n",
    "    ibdmix = pd.read_csv(filename, sep='\\t', names=['chrom', 'start', 'end', \"LOD\", \"IID\", \n",
    "                                                    \"pop\", \"super_pop\"])\n",
    "    ibdmix['length'] = (ibdmix.end - ibdmix.start)\n",
    "    return ibdmix\n",
    "\n",
    "def load_npz(fn):\n",
    "    arr = np.load(fn, allow_pickle=True)\n",
    "    arr = arr['arr_0']\n",
    "    return arr\n",
    "\n",
    "def sort_individuals(df, K):\n",
    "    \"\"\"\n",
    "    Sort individuals by modal ancestry components and it's intensity\n",
    "    :param df: pd.DataFrame, data frame containing ancestry porportions\n",
    "    :param K: int, K used to run admixture\n",
    "    :return: pd.DataFrame, sorted df\n",
    "    \"\"\"\n",
    "    # get mean ancestry per component for each population\n",
    "    mean_ancestry_pops = df.groupby('population').mean()\n",
    "    # identify modal component for each population, i.e., the component with the highest ancestry proportion\n",
    "    modal_clusters_pops = mean_ancestry_pops.idxmax(axis=1).sort_values()\n",
    "    individual_orders = []\n",
    "    # iterate over all k\n",
    "    for i in df.columns[:-1]:\n",
    "        # get all populations for which the current component is model\n",
    "        pops = modal_clusters_pops[modal_clusters_pops == i].index.values.tolist()\n",
    "        # sort the population by they mean ancestry proportions of the modal component\n",
    "        pops_sorted = mean_ancestry_pops.loc[pops, i].sort_values(ascending=False).index.values\n",
    "        inds = []\n",
    "        # sort the individuals within a population by ancestry proportion\n",
    "        for pop in pops_sorted:\n",
    "            inds.extend(df.loc[df.population == pop, i].sort_values(ascending=False).index.values.tolist())\n",
    "        individual_orders.extend(inds)\n",
    "\n",
    "    df = df.loc[individual_orders, :]\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_admixture_proportions(df, K):\n",
    "    \"\"\"\n",
    "    Create horizontal bar plot of ADMIXTURE results\n",
    "    :param df: pd.DataFrame, sorted DataFrame with ancestry proportions\n",
    "    :param K: int, K used for admixture run\n",
    "    \"\"\"\n",
    "    colors = [\"red\", \"blue\", \"green\", 'orange']\n",
    "    # pad colors\n",
    "    while K > len(colors):\n",
    "        colors.append((np.random.random(), np.random.random(), np.random.random()))\n",
    "    fig, ax = plt.subplots(figsize=(8, 2))\n",
    "    populations = df.population.values\n",
    "    x_coords = [0]\n",
    "    x_ticks = []\n",
    "    x_labels = []\n",
    "    prev_pop = populations[0]\n",
    "    pop_coord_start = 0\n",
    "    cumulative_padding = 0\n",
    "    padding = 2\n",
    "    for i, pop in enumerate(populations[1:], 1):\n",
    "        if prev_pop != pop:\n",
    "            # get ytick positions and labels\n",
    "            x_ticks.append((pop_coord_start + i + cumulative_padding - 1) / 2)\n",
    "            if prev_pop == 'AA':\n",
    "                x_labels.append('AOU-Admixed')\n",
    "            else:\n",
    "                x_labels.append(prev_pop)\n",
    "            prev_pop = pop\n",
    "            # add white space between populations\n",
    "            cumulative_padding += padding\n",
    "            pop_coord_start = i + cumulative_padding\n",
    "        # determine y coords --> add white space between populations\n",
    "        x_coords.append(i + cumulative_padding)\n",
    "    x_ticks.append((pop_coord_start + i + cumulative_padding) / 2)\n",
    "    if prev_pop == 'AA':\n",
    "        x_labels.append('AOU-Admixed')\n",
    "    else:\n",
    "        x_labels.append(prev_pop)\n",
    "    prev_k = []\n",
    "    # do plotting\n",
    "    for i, anc in enumerate(df.columns[:-1]):\n",
    "        if i > 0:\n",
    "            ax.bar(x_coords, df.loc[:, anc], bottom=df.loc[:, prev_k].sum(axis=1), width=1, color=colors[i])\n",
    "        else:\n",
    "            ax.bar(x_coords, df.loc[:, anc], width=1, color=colors[i])\n",
    "        prev_k.append(anc)\n",
    "    # formatting\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(x_labels, fontsize=10)\n",
    "    ax.set_yticks(np.arange(0, 1.2, 0.2))\n",
    "    ax.invert_xaxis()\n",
    "    ax.set_ylabel(f\"K={K}\", fontsize=12)\n",
    "    ax.set_xlim([len(populations) + cumulative_padding - 0.5, -0.5])\n",
    "    ax.set_ylim([0, 1])\n",
    "    return fig, ax\n",
    "\n",
    "def read_flare(fname_pattern):\n",
    "    dfs = []\n",
    "    for chrom in range(1, 23):\n",
    "        phase_0 = pd.read_csv(fname_pattern.format(chrom=chrom, phase=0),\n",
    "                             header=0, sep='\\t')\n",
    "        phase_0['phase'] = 0\n",
    "        phase_1 = pd.read_csv(fname_pattern.format(chrom=chrom, phase=1),\n",
    "                             header=0, sep='\\t')\n",
    "        phase_1['phase'] = 1\n",
    "        dfs.append(phase_0)\n",
    "        dfs.append(phase_1)\n",
    "    df = pd.concat(dfs)\n",
    "    df['length'] = df.end - df.start\n",
    "    return df\n",
    "\n",
    "\n",
    "def linear_regression(x, y, full_range=False):\n",
    "    reg = linregress(x, y)\n",
    "    if not full_range:\n",
    "        x2 = np.linspace(x.min(), x.max(), 100)\n",
    "    else:\n",
    "        x2 = np.linspace(min([x.min(), y.min()]), \n",
    "                         max([x.max(), y.max()]), 100)\n",
    "    y2 = x2 * reg.slope + reg.intercept\n",
    "#     https://github.com/BMClab/BMC/blob/0c338ecf74798379d724a0f27f399c96b7aecbe3//notebooks/CurveFitting.ipynb\n",
    "    # Confidence interval for the linear fit:\n",
    "    zscore = t.ppf(0.975, x.shape[0] - 2)\n",
    "    s_err = s_err = np.sqrt(np.sum((y - (x * reg.slope + reg.intercept))**2)/(x.shape[0] - 2))\n",
    "    ci = zscore * s_err * np.sqrt(1 / x.shape[0] + (x2 - np.mean(x))**2/np.sum((x2 - np.mean(x))**2))\n",
    "    # Prediction interval for the linear fit:\n",
    "    pi = zscore * s_err * np.sqrt(1 + 1 / x.shape[0] + (x2 - np.mean(x))**2 / np.sum((x2 - np.mean(x))**2))\n",
    "    print(f'Slope: {reg.slope} 95% CI: {reg.slope - reg.stderr * 1.96} - {reg.slope + reg.stderr * 1.96}')\n",
    "    print(f'Intercept: {reg.intercept} 95% CI: {reg.intercept - reg.intercept_stderr * 1.96} - {reg.intercept + reg.intercept_stderr * 1.96}')\n",
    "    \n",
    "    return reg.slope, reg.intercept, reg.rvalue, reg.pvalue, x2, y2, ci, pi\n",
    "    \n",
    "\n",
    "def make_violinplot(amounts, position, ax, color, width=0.5, alpha=1):\n",
    "    parts = ax.violinplot(amounts, showmedians=True, positions=[position], widths=width)\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor(color)\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_linewidth(0.1)\n",
    "        pc.set_alpha(alpha)\n",
    "    parts['cmedians'].set_color('black')\n",
    "    parts['cmins'].set_color('black')\n",
    "    parts['cmaxes'].set_color('black')\n",
    "    parts['cbars'].set_color('black')\n",
    "    return ax\n",
    "\n",
    "def compare_amounts_predicted_introgressed_sequence_by_populations(df, neanderthal, ax=None, fig=None):\n",
    "    if ax is None or fig is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    amounts = df.groupby(['super_pop', 'pop', 'IID']).sum().loc[:, 'length'] / 1e6\n",
    "    super_pops = amounts.index.get_level_values(0).unique()\n",
    "    n = 0\n",
    "    xlabels = []\n",
    "    for super_pop, color in zip(['EAS', 'EUR', 'AFR', 'AMR'], \n",
    "                                ['Greens_r', 'Blues_r', 'Reds_r', 'purple']):\n",
    "        if super_pop in super_pops:\n",
    "            c_amounts = amounts.loc[(super_pop, slice(None), slice(None))]\n",
    "        else:\n",
    "            continue\n",
    "        populations = c_amounts.index.get_level_values(0).unique()\n",
    "        if len(populations) > 1:\n",
    "            cmap = plt.colormaps[color]\n",
    "        else:\n",
    "            cmap = color\n",
    "        for i, pop in enumerate(populations, 1):\n",
    "            try:\n",
    "                ax = make_violinplot(c_amounts.loc[pop, :], n, ax, cmap(i * 30))\n",
    "            except TypeError:\n",
    "                ax = make_violinplot(c_amounts.loc[pop, :], n, ax, cmap)\n",
    "            n += 1\n",
    "            if pop == 'AA':\n",
    "                xlabels.append('AOU-\\nAdmixed')\n",
    "            else:\n",
    "                xlabels.append(pop)\n",
    "    ax.set_xticks(np.arange(0, len(xlabels)))\n",
    "    ax.set_xticklabels(xlabels, rotation=60)\n",
    "    ax.set_ylabel(f'{neanderthal} introgressed\\nper individual (Mb)')\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_haplotype_frequencies(df, column, chrom, ax, alpha, color):\n",
    "    c_starts = df.loc[df.chrom == chrom, 'start'].values / 1e6\n",
    "#     c_freqs = df.loc[df.chrom == chrom, column].values\n",
    "    c_ends = df.loc[df.chrom == chrom, 'end'].values / 1e6\n",
    "    ax.bar(c_starts, 1, c_ends - c_starts, align='edge', color=color, alpha=alpha)\n",
    "    return ax\n",
    "\n",
    "# def plot_introgression_landscape(df, selected, columns, colors, alpha=None, fig=None, ax=None):\n",
    "#     while len(alpha) < len(columns):\n",
    "#         alpha.append(1)\n",
    "#     while len(colors) < len(columns):\n",
    "#         colors.append((np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)))\n",
    "#     if fig is None or ax is None:\n",
    "#         fig, ax = plt.subplots(22, 1, figsize=(16, 16), sharex=True)\n",
    "#         max_freq = df.loc[:, columns].max().max() + 0.02\n",
    "#     else:\n",
    "#         max_freq = max([df.loc[:, columns].max().max(), ax[0].get_ylim()[1]])\n",
    "#     for chrom, start, end in selected.loc[:, ['chrom', 'start', 'end']].values:\n",
    "#         ax[chrom - 1].plot([start, end], [0, 0], c='black', zorder=1)\n",
    "#     for column, color, a in zip(columns, colors, alpha):\n",
    "#         for chrom in range(22):\n",
    "#             ax = plot_haplotype_frequencies(df.loc[:, ['chrom', 'start', \n",
    "#                                                        'end', column]].rename(columns={column: 'freq'}), \n",
    "#                                             chrom, ax, a, color)\n",
    "\n",
    "#             ax[chrom].set_yticks([max_freq / 2])\n",
    "#             ax[chrom].set_yticklabels([chrom + 1])\n",
    "#             ax[chrom].set_ylim([0, max_freq])\n",
    "#             for spine in ax[chrom].spines.values():\n",
    "#                 spine.set_visible(False)\n",
    "#             if chrom != 21:\n",
    "#                 ax[chrom].tick_params(axis='both', bottom=False, left=False)\n",
    "#             else:\n",
    "#                 ax[chrom].tick_params(axis='both', bottom=True, left=False)\n",
    "\n",
    "#     ax[chrom].set_xlabel('Coordinates in Mb')\n",
    "\n",
    "#     return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Global ancestries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "admixture_proportions = pd.read_csv(f'data/merged_datasets/ancestry_proportions-20.7.Q', sep='\\t', \n",
    "                                    header=0, index_col=0)\n",
    "# retain only admixed individuals\n",
    "aa_individuals = pd.read_csv('data/AA_sample_ids.txt', names=['sample'])\n",
    "admixture_proportions = admixture_proportions[np.isin(admixture_proportions.index.values, \n",
    "                                                      aa_individuals['sample'].values)]\n",
    "admixture_proportions.drop('SelfReportedRaceEthnicity', inplace=True, axis=1)\n",
    "# add population for downstream compatibility\n",
    "admixture_proportions['population'] = 'AA'\n",
    "admixture_proportions.rename(columns={'African': 'AFR', 'European': 'EUR', 'EastAsian': 'EAS'}, inplace=True)\n",
    "# aggregate Asian ancestries to EAS\n",
    "admixture_proportions.EAS += admixture_proportions.SouthAsian\n",
    "admixture_proportions.EAS += admixture_proportions.Oceania\n",
    "admixture_proportions.EAS += admixture_proportions.WestAsian\n",
    "admixture_proportions.EAS += admixture_proportions.NativeAmerican\n",
    "# drop aggregated ancestries\n",
    "admixture_proportions.drop(['SouthAsian', 'Oceania', 'WestAsian', 'NativeAmerican'], axis=1, inplace=True)\n",
    "# divide 100\n",
    "admixture_proportions.loc[:, ['AFR', 'EUR', 'EAS']] /= 100\n",
    "# sort\n",
    "admixture_proportions.sort_values(['AFR', 'EUR', 'EAS'], inplace=True)\n",
    "admixture_proportions.index = admixture_proportions.index.values.astype(str)\n",
    "# plot\n",
    "# fig, ax = plot_admixture_proportions(admixture_proportions, K)\n",
    "# fig.savefig('visualizations/admixture.pdf', bbox_inches='tight', dpi=600)\n",
    "# fig.savefig('visualizations/admixture.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### Local ancestries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_sizes = pd.read_csv('data/reference/hg38.chrom.sizes.bed', sep='\\t', names=['chrom', 'start', 'end'])\n",
    "flare_global = pd.read_csv('results50kb_wo_PEGS/flare/african_american_and_ref_individuals_chr1.global.anc.gz',\n",
    "                           sep='\\t')\n",
    "flare_global.set_index('SAMPLE', inplace=True)\n",
    "flare_global.sort_index()\n",
    "flare_global *= chrom_sizes.loc[chrom_sizes.chrom == 'chr1', 'end'].values[0] / chrom_sizes['end'].sum()\n",
    "for chrom in range(2, 23):\n",
    "    c_flare_global = pd.read_csv(f'results50kb_wo_PEGS/flare/african_american_and_ref_individuals_chr{chrom}.global.anc.gz', \n",
    "                                 sep='\\t')\n",
    "    c_flare_global.set_index('SAMPLE', inplace=True)\n",
    "    c_flare_global.sort_index()\n",
    "    c_flare_global *= (chrom_sizes.loc[chrom_sizes.chrom == f'chr{chrom}', 'end'].values[0] / \n",
    "                       chrom_sizes['end'].sum())\n",
    "    flare_global += c_flare_global\n",
    "    \n",
    "flare_global.index = flare_global.index.values.astype(str)\n",
    "# join\n",
    "flare_global = admixture_proportions.join(flare_global, rsuffix='_flare')\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10,6))\n",
    "plt.subplots_adjust(wspace=0.45)\n",
    "(slope_eas, intercept_eas, rval_eas, \n",
    " pval_eas, x_model_eas, y_model_eas, ci_eas, pi_eas) = linear_regression(flare_global.EAS, \n",
    "                                                                         flare_global.EAS_flare,\n",
    "                                                                         full_range=True)\n",
    "(slope_eur, intercept_eur, rval_eur, \n",
    " pval_eur, x_model_eur, y_model_eur, ci_eur, pi_eur) = linear_regression(flare_global.EUR, \n",
    "                                                                         flare_global.EUR_flare,\n",
    "                                                                         full_range=True)\n",
    "(slope_afr, intercept_afr, rval_afr, \n",
    " pval_afr, x_model_afr, y_model_afr, ci_afr, pi_afr) = linear_regression(flare_global.AFR, \n",
    "                                                                         flare_global.AFR_flare,\n",
    "                                                                         full_range=True)\n",
    "ax[2].scatter(flare_global.EAS, flare_global.EAS_flare, s=1, c='green')\n",
    "ax[2].plot(x_model_eas, y_model_eas, ls='--', color='black')\n",
    "# ax[2].fill_between(x_model_eas, y_model_eas + ci_eas, y_model_eas - ci_eas, color=\"black\", alpha=0.6)\n",
    "if pval_eas <= 10e-6:\n",
    "    ax[2].annotate('m={:.2f}; '.format(slope_eas) + r'$p \\leq 10^{-6}$; ' + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_eas ** 2), (1, 1), (0.05, 0.93), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "else:\n",
    "    ax[2].annotate('m={:.2f}; p={:.2e}; '.format(slope_eas, pval_eas) + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_eas ** 2), (1, 1), (0.05, 0.93), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "ax[1].scatter(flare_global.EUR, flare_global.EUR_flare, s=1, c='blue', alpha=0.7)\n",
    "ax[1].plot(x_model_eur, y_model_eur, ls='--', color='black')\n",
    "# ax[1].fill_between(x_model_eur, y_model_eur + ci_eur, y_model_eur - ci_eur, color=\"black\", alpha=0.6)\n",
    "if pval_eur <= 10e-6:\n",
    "    ax[1].annotate('m={:.2f}; '.format(slope_eur) + r'$p \\leq 10^{-6}$; ' + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_eur ** 2), (1, 1), (0.05, 0.93), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "else:\n",
    "    ax[1].annotate('m={:.2f}; p={:.2e}; '.format(slope_eur, pval_eur) + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_eur ** 2), (1, 1), (0.05, 0.93), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "\n",
    "ax[0].scatter(flare_global.AFR, flare_global.AFR_flare, s=1, c='red')\n",
    "ax[0].plot(x_model_afr, y_model_afr, ls='--', color='black')\n",
    "# ax[0].fill_between(x_model_afr, y_model_afr + ci_afr, y_model_afr - ci_afr, color=\"black\", alpha=0.6)\n",
    "if pval_afr <= 10e-6:\n",
    "    ax[0].annotate('m={:.2f}; '.format(slope_afr) + r'$p \\leq 10^{-6}$; ' + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_afr ** 2), (1, 1), (0.05, 0.93), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "else:\n",
    "    ax[0].annotate('a={:.2f}; p={:.2e}; '.format(slope_afr, pval_afr) + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_afr ** 2), (1, 1), (0.05, 0.93), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "\n",
    "ax[2].set_aspect('equal')\n",
    "ax[1].set_aspect('equal')\n",
    "ax[0].set_aspect('equal')\n",
    "ax[2].set_xlim([0, 0.06])\n",
    "ax[2].set_ylim([0, 0.06])\n",
    "ax[1].set_xlim([0.05, 0.55])\n",
    "ax[1].set_ylim([0.05, 0.55])\n",
    "ax[0].set_xlim([0.45, 0.95])\n",
    "ax[0].set_ylim([0.45, 0.95])\n",
    "\n",
    "ax[0].set_ylabel('FLARE AFR-like\\nancestry estimate', fontsize=9)\n",
    "ax[1].set_ylabel('FLARE EUR-like\\nancestry estimate', fontsize=9)\n",
    "ax[2].set_ylabel('FLARE EAS-like\\nancestry estimate', fontsize=9)\n",
    "\n",
    "ax[2].set_xlabel('Rye EAS-like ancestry estimate', fontsize=9)\n",
    "ax[1].set_xlabel('Rye EUR-like ancestry estimate', fontsize=9)\n",
    "ax[0].set_xlabel('Rye AFR-like ancestry estimate', fontsize=9)\n",
    "ax[0].annotate(\"A\", (1, 1), (-.3, 0.95), xycoords='axes fraction', fontsize=14, fontweight='bold')\n",
    "ax[1].annotate(\"B\", (1, 1), (-.3, 0.95), xycoords='axes fraction', fontsize=14, fontweight='bold')\n",
    "ax[2].annotate(\"C\", (1, 1), (-.33, 0.95), xycoords='axes fraction', fontsize=14, fontweight='bold')\n",
    "\n",
    "fig.savefig('visualizations/corr_rye_flare_global_ancestry.pdf', bbox_inches='tight', dpi=600)\n",
    "fig.savefig('visualizations/corr_rye_flare_global_ancestry.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_ancestry_fname_pattern = 'results50kb_wo_PEGS/flare/african_american_and_ref_individuals_chr{chrom}.anc_per_pos.phase{phase}.Vindija33.19.bed'\n",
    "local_ancestry = read_flare(local_ancestry_fname_pattern)\n",
    "local_ancestry.IID = local_ancestry.IID.values.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Plot introgressed amounts per individual per population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdmix = read_ibdmix_results('results50kb_wo_PEGS/ibdmix_Vindija33.19/ibdmix_results_masked_denisovan_combined_50kb_4.0LOD.bed')\n",
    "ibdmix_masked = read_ibdmix_results('results50kb_wo_PEGS/ibdmix_Vindija33.19/ibdmix_results_masked_denisovan_combined_50kb_4.0LOD_afr_masked.bed')\n",
    "ibdmix.replace({\"AOUNA\": \"AOU-NA\", 'AOUAFR': 'AOU-AFR', 'PEGS': 'PEGS-EUR', 'AOUEUR': 'AOU-EUR'}, inplace=True)\n",
    "ibdmix.replace({population: f'1KGP-{population}' for population in ibdmix['pop'].unique() \n",
    "                if not population.startswith('AOU-') and population != 'AA'}, inplace=True)\n",
    "\n",
    "ibdmix_masked.replace({\"AOUNA\": \"AOU-NA\", 'AOUAFR': 'AOU-AFR', 'PEGS': 'PEGS-EUR', 'AOUEUR': 'AOU-EUR'},\n",
    "                      inplace=True)\n",
    "ibdmix_masked.replace({population: f'1KGP-{population}' for population in ibdmix_masked['pop'].unique()\n",
    "                       if not population.startswith('AOU-') and population != 'AA'}, inplace=True)\n",
    "fig, ax = compare_amounts_predicted_introgressed_sequence_by_populations(ibdmix, 'Vindija33.19')\n",
    "fig1, ax1 = compare_amounts_predicted_introgressed_sequence_by_populations(ibdmix_masked, \n",
    "                                                                           'Vindija33.19 AFR-masked')\n",
    "# fig.savefig('visualizations/amounts_neanderthal_global.pdf', bbox_inches='tight', dpi=600)\n",
    "# fig.savefig('visualizations/amounts_neanderthal_global.png', bbox_inches='tight', dpi=600)\n",
    "\n",
    "fig1.savefig('visualizations/amounts_neanderthal_global_afr_masked.pdf', bbox_inches='tight', dpi=600)\n",
    "fig1.savefig('visualizations/amounts_neanderthal_global_afr_masked.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Overlap of introgressed segments with local ancestry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlap_local_ancestry_neanderthal_segments(args):\n",
    "    ibdmix, local_ancestry, iids = args\n",
    "    afr_enrichment = []\n",
    "    eur_enrichment = []\n",
    "    eas_enrichment = []\n",
    "    columns = local_ancestry.columns.values\n",
    "    columns = np.concatenate([columns, [col + '_nea' for col in ibdmix.columns.values], ['overlap']])\n",
    "    for iid in iids:\n",
    "        c_ibdmix = ibdmix[ibdmix.IID == iid]\n",
    "        c_local_ancestry = local_ancestry[local_ancestry.IID == iid]\n",
    "        overlap = BedTool.from_dataframe(c_local_ancestry).intersect(BedTool.from_dataframe(c_ibdmix), \n",
    "                                                             wao=True).to_dataframe(names=columns)\n",
    "        ancestry_prop = (c_local_ancestry.groupby('la')['length'].sum() / \n",
    "                         c_local_ancestry.groupby('la')['length'].sum().sum())\n",
    "        nea_overlap = overlap.groupby('la')['overlap'].sum() / overlap.groupby('la')['overlap'].sum().sum()\n",
    "        afr_enrichment.append(nea_overlap[\"AFR\"] / ancestry_prop['AFR'])\n",
    "        eur_enrichment.append(nea_overlap[\"EUR\"] / ancestry_prop['EUR'])\n",
    "        try:\n",
    "            eas_enrichment.append(nea_overlap[\"EAS\"] / ancestry_prop['EAS'])\n",
    "        except KeyError:\n",
    "            eas_enrichment.append(0.0)\n",
    "    return (afr_enrichment, eur_enrichment, eas_enrichment)\n",
    "\n",
    "amr_iids = ibdmix.loc[ibdmix.super_pop == 'AMR', 'IID'].unique()\n",
    "splits = np.array_split(amr_iids, 8)\n",
    "ready_to_map = [(ibdmix, local_ancestry, split) for split in splits]\n",
    "pool = mp.Pool(processes=16)\n",
    "results = pool.map(get_overlap_local_ancestry_neanderthal_segments, ready_to_map)\n",
    "pool.close()\n",
    "pool.join()\n",
    "afr_enrichment = np.concatenate([res[0] for res in results])\n",
    "eur_enrichment = np.concatenate([res[1] for res in results])\n",
    "eas_enrichment = np.concatenate([res[2] for res in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(afr_enrichment, bins=100, color='red', alpha=0.7, label='AFR', density=True, \n",
    "        range=(min([min(afr_enrichment), min(eur_enrichment)]), \n",
    "               max([max(afr_enrichment), max(eur_enrichment)])))\n",
    "ax.hist(eur_enrichment, bins=100, color='blue', alpha=0.7, label='EUR', density=True,\n",
    "        range=(min([min(afr_enrichment), min(eur_enrichment)]), \n",
    "               max([max(afr_enrichment), max(eur_enrichment)])))\n",
    "# ax.hist(eas_enrichment, bins=100, color='green', alpha=0.7, label='EAS', density=True)\n",
    "ax.legend()\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_xlabel('Neanderthal ancestry enrichment in local ancestry')\n",
    "fig.savefig('visualizations/nea_enrichment_in_local_ancestry.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Plot introgressed amount vs ancestry proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "neanderthal = 'Vindija33.19'\n",
    "# calculate introgressed amount per individual\n",
    "amounts = ibdmix.groupby('IID').sum().loc[:, ['length']] / 1e6\n",
    "# join with admixture proportions\n",
    "amounts = amounts.join(admixture_proportions)\n",
    "# select admixed individuals only\n",
    "amounts = amounts[amounts.population == 'AA']\n",
    "# regress introgressed amounts against admixture proportions\n",
    "\n",
    "(slope_afr, intercept_afr, rval_afr, pval_afr, \n",
    " x_model_afr, y_model_afr, ci_afr, pi_afr) = linear_regression(amounts.AFR, amounts['length'])\n",
    "(slope_eas, intercept_eas, rval_eas, pval_eas, \n",
    " x_model_eas, y_model_eas, ci_eas, pi_eas) = linear_regression(amounts.EAS, amounts['length'])\n",
    "(slope_eur, intercept_eur, rval_eur, pval_eur, \n",
    " x_model_eur, y_model_eur, ci_eur, pi_eur) = linear_regression(amounts.EUR, amounts['length'])\n",
    "lm = ols('length ~ EUR + EAS + AFR', data=amounts).fit()\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = fig.add_gridspec(2, 3)\n",
    "ax = fig.add_subplot(gs[0, :])\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax2 = fig.add_subplot(gs[1, 1])\n",
    "ax3 = fig.add_subplot(gs[1, 2])\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "fig, ax = compare_amounts_predicted_introgressed_sequence_by_populations(ibdmix, 'Vindija33.19', \n",
    "                                                                         ax=ax, fig=fig)\n",
    "\n",
    "\n",
    "ax3.scatter(amounts.EAS, amounts['length'].values, color='green', s=2, alpha=0.5)\n",
    "ax3.plot(x_model_eas, y_model_eas, ls='--', color='black')\n",
    "# ax3.fill_between(x_model_eas, y_model_eas + ci_eas, y_model_eas - ci_eas, color=\"black\", alpha=0.4)\n",
    "if pval_eas <= 10e-6:\n",
    "    ax3.annotate(r'$p \\leq 10^{-6}$; ' + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_eas ** 2), (1, 1), (0.5, 0.95), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "else:\n",
    "    ax3.annotate(r'p={:.2e}; '.format(pval_eas) + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_eas ** 2), (1, 1), (0.5, 0.95), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "# ax[0].plot(x_model_eas, y_model_eas + pi_eas, ls=':', color='black')\n",
    "# ax[0].plot(x_model_eas, y_model_eas - pi_eas, ls=':', color='black')\n",
    "\n",
    "ax2.scatter(amounts.EUR, amounts['length'].values, color='blue', s=2, alpha=0.5)\n",
    "ax2.plot(x_model_eur, y_model_eur, ls='--', color='black')\n",
    "# ax2.fill_between(x_model_eur, y_model_eur + ci_eur, y_model_eur - ci_eur, color=\"black\", alpha=0.4)\n",
    "if pval_eur <= 10e-6:\n",
    "    ax2.annotate(r'$p \\leq 10^{-6}$; ' + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_eur ** 2), (1, 1), (0.05, 0.95), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "else:\n",
    "    ax2.annotate(r'p={:.2e}; '.format(pval_eur) + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_eur ** 2), (1, 1), (0.05, 0.95), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "# ax[1].plot(x_model_eur, y_model_eur + pi_eur, ls=':', color='black')\n",
    "# ax[1].plot(x_model_eur, y_model_eur - pi_eur, ls=':', color='black')\n",
    "\n",
    "ax1.scatter(amounts.AFR, amounts['length'].values, color='red', s=2, alpha=0.5)\n",
    "ax1.plot(x_model_afr, y_model_afr, ls='--', color='black')\n",
    "# ax1.fill_between(x_model_afr, y_model_afr + ci_afr, y_model_afr - ci_afr, color=\"black\", alpha=0.4)\n",
    "if pval_afr <= 10e-6:\n",
    "    ax1.annotate(r'$p \\leq 10^{-6}$; ' + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_afr ** 2), (1, 1), (0.5, 0.95), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "else:\n",
    "    ax1.annotate(r'p={:.2e}; '.format(pval_afr) + r'$r$' + \n",
    "                   '={:.2f}'.format(rval_afr ** 2), (1, 1), (0.5, 0.95), \n",
    "                   xycoords='axes fraction', fontsize=8)\n",
    "# ax[2].plot(x_model_afr, y_model_afr + pi_afr, ls=':', color='black')\n",
    "# ax[2].plot(x_model_afr, y_model_afr - pi_afr, ls=':', color='black')\n",
    "\n",
    "ax1.set_ylabel(f'{neanderthal} introgressed\\nper individual (Mb)')\n",
    "ax3.set_xlabel('EAS-/NA-like ancestry proportion')\n",
    "ax2.set_xlabel('EUR-like ancestry proportion')\n",
    "ax1.set_xlabel('AFR-like ancestry proportion')\n",
    "yticklabels = ax1.get_yticklabels()\n",
    "ax2.set_yticklabels([])\n",
    "ax3.set_yticklabels([])\n",
    "ax.annotate(\"A\", (1, 1), (-0.08, 0.92), xycoords='axes fraction', fontsize=16, fontweight='bold')\n",
    "ax1.annotate(\"B\", (1, 1), (-0.28, 0.92), xycoords='axes fraction', fontsize=16, fontweight='bold')\n",
    "ax2.annotate(\"C\", (1, 1), (-0.15, 0.92), xycoords='axes fraction', fontsize=16, fontweight='bold')\n",
    "ax3.annotate(\"D\", (1, 1), (-0.15, 0.92), xycoords='axes fraction', fontsize=16, fontweight='bold')\n",
    "\n",
    "fig.savefig(\"visualizations/figure2.pdf\", bbox_inches='tight', dpi=600)\n",
    "fig.savefig(\"visualizations/figure2.png\", bbox_inches='tight', dpi=600)\n",
    "\n",
    "# ax1.set_yticklabels(yticklabelslabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_amount_per_super_pop(df):\n",
    "    super_pop_indv_mapping = df.drop_duplicates(\"IID\").loc[:, [\"IID\", 'super_pop']].set_index('IID')\n",
    "    # groupby individual\n",
    "    amount_introgression_per_indv = df.loc[:, ['IID', 'length']].groupby('IID').sum() / 1e6\n",
    "    amount_introgression_superpop_per_indv = super_pop_indv_mapping.join(amount_introgression_per_indv)\n",
    "    mean_introgression_per_superpop = amount_introgression_superpop_per_indv.groupby('super_pop').mean()\n",
    "    return mean_introgression_per_superpop\n",
    "get_average_amount_per_super_pop(ibdmix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_average_amount_per_super_pop(ibdmix_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Compare unique introgressed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_unique_sequence_super_pop(df, super_pop, bootstrap=False, n_indvs=13844):\n",
    "    df = df[df.super_pop == super_pop]\n",
    "    if bootstrap:\n",
    "        iids = df[df.super_pop == super_pop].IID.unique()\n",
    "        b_iids = np.random.choice(iids, size=(n_indvs, 100))\n",
    "        df.set_index('IID', inplace=True)\n",
    "        unique = []\n",
    "        for i in tqdm(range(100)):\n",
    "            c_df = df.loc[b_iids[:, i]].sort_values(['chrom', 'start'])\n",
    "            c_unique = BedTool.from_dataframe(c_df).merge().to_dataframe()\n",
    "            c_unique['length'] = c_unique.end - c_unique.start\n",
    "            unique.append(c_unique['length'].sum() / 1e6)\n",
    "    else:\n",
    "        unique = BedTool.from_dataframe(df).merge().to_dataframe()\n",
    "        unique['length'] = unique.end - unique.start\n",
    "        unique = unique['length'].sum() / 1e6\n",
    "    return unique\n",
    "\n",
    "\n",
    "print(\"EUR: \" + str(get_total_unique_sequence_super_pop(ibdmix_masked[ibdmix_masked.super_pop =='EUR'].groupby('IID').sample(frac=0.233).sort_values(['chrom', 'start']), 'EUR')))\n",
    "# print(\"Admixed: \" + str(get_total_unique_sequence_super_pop(ibdmix_masked, 'AMR')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_admixed = get_total_unique_sequence_super_pop(ibdmix_masked, 'AMR', bootstrap=True)\n",
    "print(\"Admixed: \" + str(np.mean(unique_admixed)) + \"(\" + str(np.percentile(unique_admixed, 2.5)) + \"-\" +\n",
    "      str(np.percentile(unique_admixed, 97.5)) + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdmix_masked[ibdmix_masked.super_pop == 'AMR'].IID.value_counts().mean() /ibdmix_masked[ibdmix_masked.super_pop == 'EUR'].IID.value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_amount_per_pop(df):\n",
    "    pop_indv_mapping = df.drop_duplicates(\"IID\").loc[:, [\"IID\", 'pop']].set_index('IID')\n",
    "    # groupby individual\n",
    "    amount_introgression_per_indv = df.loc[:, ['IID', 'length']].groupby('IID').sum() / 1e6\n",
    "    amount_introgression_pop_per_indv = pop_indv_mapping.join(amount_introgression_per_indv)\n",
    "    mean_introgression_per_pop = amount_introgression_pop_per_indv.groupby('pop').mean()\n",
    "    return mean_introgression_per_pop\n",
    "\n",
    "\n",
    "unique_eur = BedTool.from_dataframe(ibdmix_masked[ibdmix_masked.super_pop == 'EUR']).intersect(\n",
    "    BedTool.from_dataframe(ibdmix_masked[ibdmix_masked.super_pop == 'AMR']), \n",
    "                           v=True).to_dataframe(names=ibdmix_masked.columns)\n",
    "get_average_amount_per_pop(unique_eur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_unique_sequence_pop(df, population, bootstrap=False, n_indvs=None):\n",
    "    df = df[df['pop'] == population]\n",
    "    if bootstrap:\n",
    "        iids = df.IID.unique()\n",
    "        b_iids = np.random.choice(iids, size=(n_indvs, 100))\n",
    "        df.set_index('IID', inplace=True)\n",
    "        unique = []\n",
    "        for i in tqdm(range(100)):\n",
    "            c_df = df.loc[b_iids[:, i]].sort_values(['chrom', 'start'])\n",
    "            c_unique = BedTool.from_dataframe(c_df).merge().to_dataframe()\n",
    "            c_unique['length'] = c_unique.end - c_unique.start\n",
    "            unique.append(c_unique['length'].sum() / 1e6)\n",
    "    else:\n",
    "        unique = BedTool.from_dataframe(df).merge().to_dataframe()\n",
    "        unique['length'] = unique.end - unique.start\n",
    "        unique = unique['length'].sum() / 1e6\n",
    "    return unique\n",
    "\n",
    "print(\"AOU-EUR: \" + str(get_total_unique_sequence_pop(unique_eur, 'AOU-EUR')))\n",
    "print(\"PEGS-EUR: \" + str(get_total_unique_sequence_pop(unique_eur, 'PEGS-EUR')))\n",
    "print(\"CEU: \" + str(get_total_unique_sequence_pop(unique_eur, 'CEU')))\n",
    "print(\"GBR: \" + str(get_total_unique_sequence_pop(unique_eur, 'GBR')))\n",
    "print(\"IBS: \" + str(get_total_unique_sequence_pop(unique_eur, 'IBS')))\n",
    "print(\"TSI: \" + str(get_total_unique_sequence_pop(unique_eur, 'TSI')))\n",
    "print(\"FIN: \" + str(get_total_unique_sequence_pop(unique_eur, 'FIN')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_aou = get_total_unique_sequence_pop(unique_eur, 'AOU-EUR', bootstrap=True, n_indvs=91)\n",
    "unique_pegs = get_total_unique_sequence_pop(unique_eur, 'PEGS-EUR', bootstrap=True, n_indvs=91)\n",
    "unique_ceu = get_total_unique_sequence_pop(unique_eur, 'CEU', bootstrap=True, n_indvs=91)\n",
    "unique_gbr = get_total_unique_sequence_pop(unique_eur, 'GBR', bootstrap=True, n_indvs=91)\n",
    "unique_ibs = get_total_unique_sequence_pop(unique_eur, 'IBS', bootstrap=True, n_indvs=91)\n",
    "unique_tsi = get_total_unique_sequence_pop(unique_eur, 'TSI', bootstrap=True, n_indvs=91)\n",
    "unique_fin = get_total_unique_sequence_pop(unique_eur, 'FIN', bootstrap=True, n_indvs=91)\n",
    "\n",
    "for population, unique in zip(['AOU-EUR', 'PEGS-EUR', 'CEU', \"GBR\", \"IBS\", \"TSI\", \"FIN\"],\n",
    "                              [unique_aou, unique_pegs, unique_ceu, unique_gbr, unique_ibs, \n",
    "                               unique_tsi, unique_fin]):\n",
    "    print(f\"{population}: {np.mean(unique)} ({np.percentile(unique, 2.5)} - \"+\n",
    "          f\"{np.percentile(unique, 97.5)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Compare expected versus observed amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_expected_introgression(admixture_proportions, ibdmix):\n",
    "    # calculate introgressed amount per individual\n",
    "    amounts = ibdmix.groupby('IID').sum().loc[:, ['length']] / 1e6\n",
    "    # join with admixture proportions\n",
    "    amounts = amounts.join(admixture_proportions)\n",
    "    # select admixed individuals only\n",
    "    amounts = amounts[amounts.population == 'AA']\n",
    "    super_pop_indv_mapping = ibdmix.drop_duplicates(\"IID\").loc[:, [\"IID\", 'super_pop']].set_index('IID')\n",
    "    # groupby individual\n",
    "    amount_introgression_per_indv = ibdmix.loc[:, ['IID', 'length']].groupby('IID').sum() / 1e6\n",
    "    # calculate mean per continental population\n",
    "    amount_introgression_superpop_per_indv = super_pop_indv_mapping.join(amount_introgression_per_indv)\n",
    "    mean_introgression_per_superpop = amount_introgression_superpop_per_indv.groupby('super_pop').mean()\n",
    "    if not 'AFR' in mean_introgression_per_superpop.index:\n",
    "        mean_introgression_per_superpop.loc['AFR', 'length'] = 0.0\n",
    "    if not 'EUR' in mean_introgression_per_superpop.index:\n",
    "        mean_introgression_per_superpop.loc['EUR', 'length'] = 0.0\n",
    "    if not 'EAS' in mean_introgression_per_superpop.index:\n",
    "        mean_introgression_per_superpop.loc['EAS', 'length'] = 0.0\n",
    "    amounts['expected_introgression'] = (amounts.AFR * \n",
    "                                         mean_introgression_per_superpop.loc['AFR', 'length'] + \n",
    "                                         amounts.EUR * \n",
    "                                         mean_introgression_per_superpop.loc['EUR', 'length'] +\n",
    "                                         amounts.EAS * \n",
    "                                         mean_introgression_per_superpop.loc['EAS', 'length'])\n",
    "        \n",
    "    return amounts\n",
    "\n",
    "def plot_observed_vs_expected_amounts(amounts, color_scatter='lightblue', color_reg='blue', ax=None):\n",
    "    # do regression\n",
    "    (slope, intercept, rval, pval, x_model, y_model, \n",
    "     ci, pi) = linear_regression(amounts.expected_introgression, amounts['length'], full_range=True)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    amounts =  amounts.copy()\n",
    "    amounts.reset_index(inplace=True)\n",
    "    xy = np.vstack([amounts.expected_introgression, amounts['length']])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    # Sort the points by density, so that the densest points are plotted last\n",
    "    idx = z.argsort()\n",
    "    x, y, z = amounts.loc[idx, 'expected_introgression'], amounts.loc[idx, 'length'], z[idx]\n",
    "    cax = ax.scatter(x, y, c=z, s=2, cmap=color_scatter, \n",
    "                     norm=LogNorm(vmin=z.min(), vmax=z.max()))\n",
    "#     ax.scatter(amounts.expected_introgression.values, amounts['length'].values, c=color_scatter, s=2)\n",
    "    if intercept > 0:\n",
    "        ax.plot(x_model, y_model, ls='--', color=color_reg,\n",
    "                label=f'y={np.round(slope, 2)}x + {np.round(intercept, 2)}')\n",
    "    else:\n",
    "        ax.plot(x_model, y_model, ls='--', color=color_reg,\n",
    "                label=f'y={np.round(slope, 2)}x - {np.round(np.abs(intercept), 2)}')\n",
    "#     ax.fill_between(x_model, y_model + ci, y_model - ci, color=color_reg, alpha=0.4)\n",
    "    if pval <= 10e-6:\n",
    "        ax.annotate(r'$p\\leq10^{-6}$; ' + r'$r$' + \n",
    "                    '={:.2f}'.format(rval ** 2), (1, 1), (0.05, 0.93), \n",
    "                   xycoords='axes fraction')\n",
    "    else:\n",
    "        ax.annotate(r'p={:.2e}; '.format(pval) + r'$r$' + \n",
    "                    '={:.2f}'.format(rval ** 2), (1, 1), (0.05, 0.93), \n",
    "                       xycoords='axes fraction')\n",
    "    ax.plot(x_model, x_model, ls='--', c='black', label='y=x')\n",
    "    ax.legend(bbox_to_anchor=(0.5, -.27), loc='center', ncol=2)\n",
    "    # ax.plot(x_model, y_model + pi, ls=':', color='blue')\n",
    "    # ax.plot(x_model, y_model - pi, ls=':', color='blue')\n",
    "    ax.set_xlabel('Expected introgression per individual (Mb)')\n",
    "    ax.set_ylabel('Observed introgression\\nper individual (Mb)')\n",
    "    ax.set_xticks(ax.get_yticks())\n",
    "    min_lim = max([min([amounts.expected_introgression.min(), amounts['length'].min()]) - 1, 0])\n",
    "    max_lim = max([amounts.expected_introgression.max(), amounts['length'].max()]) + 1\n",
    "    ax.set_xlim([min_lim, max_lim])\n",
    "    ax.set_ylim([min_lim, max_lim])\n",
    "    ax.set_aspect('equal')\n",
    "    return ax, cax\n",
    "\n",
    "def plot_hist_of_ratios_of_obs_vs_exp_amounts(df, color, simulation_ratios, ax=None,\n",
    "                                              bins=np.linspace(-.2, .5, 200), \n",
    "                                              color_sim='gray'):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    for i in range(simulation_ratios.shape[0]):\n",
    "        if simulation_ratios[i].shape[0] < 900:\n",
    "#             print(i)\n",
    "            continue\n",
    "        ax.hist(np.log10(simulation_ratios[i].astype(float)), bins=bins, histtype='step', color=color_sim,\n",
    "                weights=np.repeat(1 / simulation_ratios[i].shape[0], simulation_ratios[i].shape[0]), \n",
    "                alpha=0.1)\n",
    "    ax.hist(np.log10(df['length'] / df['expected_introgression']), bins=bins, histtype='step', color=color,\n",
    "            weights=np.repeat(1 / df.shape[0], df.shape[0]), alpha=1)\n",
    "    ax.axvline(0, ls='--', color='black')\n",
    "#     test = ttest_1samp(np.log(df['length'] / df['expected_introgression']), 0)\n",
    "#     if test.pvalue <= 1e-6:\n",
    "#         ax.annotate('P' r'$\\leq$' + '{:.0e}'.format(1e-6), (1, 1), (0.8, 0.95), \n",
    "#                     xycoords='axes fraction')\n",
    "#     else:\n",
    "#         ax.annotate('P={:.3e}'.format(test.pvalue), (1, 1), (0.8, 0.95), \n",
    "#                    xycoords='axes fraction')\n",
    "    ax.axvline(0, ls='--', color='black')\n",
    "    ax.set_xlabel(r'$log10(\\frac{Observed\\ introgression\\ in\\ Mb}{Expected\\ introgression\\ in\\ Mb})$')\n",
    "    return ax\n",
    "\n",
    "def plot_hist_of_diff_of_obs_vs_exp_amounts(df, color, simulation_diffs, ax=None,\n",
    "                                            bins=np.linspace(-.2, .5, 200), \n",
    "                                            color_sim='gray'):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    pvals = []\n",
    "    for i in range(simulation_diffs.shape[0]):\n",
    "        # divide diff by simulated genome size\n",
    "        ax.hist(simulation_diffs[i] / (903043000 / 1e6) * 100, bins=bins, histtype='step', color=color_sim,\n",
    "                weights=np.repeat(1 / simulation_diffs[i].shape[0], simulation_diffs[i].shape[0]), \n",
    "                alpha=0.5)\n",
    "        pvals.append(mannwhitneyu(simulation_diffs[i].astype(float) / (903043000 / 1e6) * 100, \n",
    "                                   (df['length'].values - \n",
    "                                    df['expected_introgression'].values) / (2875001522 / 1e6) * 100).pvalue)\n",
    "    # divide diff by autosomal genome size\n",
    "    ax.hist((df['length'] - df['expected_introgression']) / (2875001522 / 1e6) * 100, bins=bins, \n",
    "            histtype='step', color=color,\n",
    "            weights=np.repeat(1 / df.shape[0], df.shape[0]), alpha=1)\n",
    "    ax.axvline(0, ls='--', color='black')\n",
    "    ax.set_xlabel('Observed - expected\\nNeanderthal admixture fraction (%)')\n",
    "#     test = ttest_1samp(np.log(df['length'] / df['expected_introgression']), 0)\n",
    "#     if hmean(pvals) <= 1e-6:\n",
    "#         ax.annotate('P' r'$\\leq$' + '{:.0e}'.format(1e-6), (1, 1), (0.6, 0.93), \n",
    "#                     xycoords='axes fraction')\n",
    "#     else:\n",
    "#         ax.annotate('P={:.3e}'.format(hmean(pvals)), (1, 1), (0.6, 0.93), \n",
    "#                    xycoords='axes fraction')\n",
    "    ax.axvline(0, ls='--', color='black')\n",
    "    return ax\n",
    "\n",
    "def load_simulations(prefix):\n",
    "    ratios = load_npz(f'{prefix}_ratios.npz')\n",
    "    ratios_short = load_npz(f'{prefix}_ratios_short_segments.npz')\n",
    "    ratios_medium = load_npz(f'{prefix}_ratios_medium_segments.npz')\n",
    "    ratios_long = load_npz(f'{prefix}_ratios_long_segments.npz')\n",
    "\n",
    "    differences = load_npz(f'{prefix}_differences.npz')\n",
    "    differences_short = load_npz(f'{prefix}_differences_short_segments.npz')\n",
    "    differences_medium = load_npz(f'{prefix}_differences_medium_segments.npz')\n",
    "    differences_long = load_npz(f'{prefix}_differences_long_segments.npz')\n",
    "\n",
    "    slopes = load_npz(f'{prefix}_slopes.npz')\n",
    "    intercepts = load_npz(f'{prefix}_intercepts.npz')\n",
    "    try:\n",
    "        lengths = load_npz(f'{prefix}_segment_lengths.npz')\n",
    "        lengths = np.concatenate(lengths) / 1000\n",
    "    except:\n",
    "        print(f\"couldn't load {prefix}_segment_lengths.npz\")\n",
    "        lengths = []\n",
    "    try:\n",
    "        lods = load_npz(f'{prefix}_segment_lods.npz')\n",
    "        lods = np.concatenate(lods)\n",
    "    except:\n",
    "        print(f\"couldn't load {prefix}_segment_lods.npz\")\n",
    "        lods = []\n",
    "    return (ratios, ratios_short, ratios_medium, ratios_long, differences, differences_short, \n",
    "            differences_medium, differences_long, slopes, intercepts, lengths, lods) \n",
    "\n",
    "# def plot_scatter_and_simulated_hist(amounts, simulations_simple, simulations_full,\n",
    "def plot_scatter_and_simulated_hist(amounts, simulations,\n",
    "                                    histrange=(-.5, .5), color_scatter='royalblue', color_reg='blue',\n",
    "                                    color_sim='blue', plot_difference=False):\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    gs_outer = fig.add_gridspec(1, 2, width_ratios=[5, 6], wspace=0.35)\n",
    "    gs2 = gridspec.GridSpecFromSubplotSpec(44, 20, subplot_spec = gs_outer[1], wspace=0.15)\n",
    "\n",
    "    ax = fig.add_subplot(gs_outer[0])\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs2[8:36, 3:])\n",
    "    bins = np.linspace(histrange[0], histrange[1], 200)\n",
    "    ax, cax = plot_observed_vs_expected_amounts(amounts, ax=ax, color_scatter=color_scatter, \n",
    "                                           color_reg=color_reg)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    c_ax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    cbar = fig.colorbar(cax, cax=c_ax, ax=ax)\n",
    "    cbar.set_label('Density')\n",
    "    if plot_difference:\n",
    "        ax1 = plot_hist_of_diff_of_obs_vs_exp_amounts(amounts, color_sim, simulations,\n",
    "                                                        ax=ax1, bins=bins)\n",
    "    else:\n",
    "        ax1 = plot_hist_of_ratios_of_obs_vs_exp_amounts(amounts, color_sim, simulations,\n",
    "                                                        ax=ax1, bins=bins)\n",
    "\n",
    "    handles = [Line2D([0], [0], ls='-', color='gray', label='Simulations'),\n",
    "               Line2D([0], [0], ls='-', color=color_sim, label='AOU-Admixed')]\n",
    "    ax1.legend(handles=handles, bbox_to_anchor=(0.5, -.2), ncol=2, loc='upper center')\n",
    "    ax1.set_ylabel('Density')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ax.annotate(\"A\", (1, 1), (-.22, 0.95), xycoords='axes fraction', fontsize=14, fontweight='bold')\n",
    "    ax1.annotate(\"B\", (1, 1), (-.2, 0.95), xycoords='axes fraction', fontsize=14, fontweight='bold')\n",
    "    return fig, ax, ax1\n",
    "\n",
    "\n",
    "amounts = calculate_expected_introgression(admixture_proportions, ibdmix)\n",
    "\n",
    "(simulations_ratios, simulations_ratios_short, \n",
    " simulations_ratios_medium, simulations_ratios_long, \n",
    " simulations_differences, simulations_differences_short, \n",
    " simulations_differences_medium, \n",
    " simulations_differences_long, simulations_slopes, \n",
    " simulations_intercepts, simulations_lengths, \n",
    " simulations_lods) = load_simulations('simulations')\n",
    "\n",
    "\n",
    "\n",
    "fig, ax, ax1 = plot_scatter_and_simulated_hist(amounts, \n",
    "                                               simulations_differences, \n",
    "                                               color_scatter='Reds', color_reg='darksalmon', \n",
    "                                               color_sim='red', plot_difference=True, \n",
    "                                               histrange=(-.5, 1))\n",
    "\n",
    "fig.savefig('visualizations/nea_enrichment.pdf', bbox_inches='tight', dpi=600)\n",
    "fig.savefig('visualizations/nea_enrichment.png', bbox_inches='tight', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((amounts['length'] - amounts['expected_introgression'])) #/ (2875001522 / 1e6) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Mask African component to check if ILS might be driving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "amounts_masked = calculate_expected_introgression(admixture_proportions, ibdmix_masked)\n",
    "\n",
    "(simulations_afr_masked_ratios, simulations_afr_masked_ratios_short, \n",
    " simulations_afr_masked_ratios_medium, simulations_afr_masked_ratios_long, \n",
    " simulations_afr_masked_differences, simulations_afr_masked_differences_short, \n",
    " simulations_afr_masked_differences_medium, \n",
    " simulations_afr_masked_differences_long, simulations_afr_masked_slopes, \n",
    " simulations_afr_masked_intercepts, simulations_afr_masked_lengths, \n",
    " simulations_afr_masked_lods) = load_simulations('simulations_afr_masked')\n",
    "\n",
    "fig, ax, ax1 = plot_scatter_and_simulated_hist(amounts_masked, \n",
    "                                               simulations_afr_masked_differences, \n",
    "                                               color_scatter='Purples', color_reg='mediumvioletred', \n",
    "                                               color_sim='purple', plot_difference=True, \n",
    "                                               histrange=(-.2, 0.5))\n",
    "\n",
    "fig.savefig('visualizations/figure3.pdf', bbox_inches='tight', dpi=600)\n",
    "fig.savefig('visualizations/figure3.png', bbox_inches='tight', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((amounts_masked['length'] - amounts_masked['expected_introgression'])) / (2875001522 / 1e6) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Load recombination filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_maps = []\n",
    "for chrom in np.arange(1, 23):\n",
    "    genetic_map = pd.read_csv(f'data/hapmap_genetic_map/genetic_map_Hg38_chr{chrom}.txt', sep='\\t')\n",
    "    genetic_map.rename({'Chromosome': 'chrom_map', 'Position(bp)': 'end_map', 'Rate(cM/Mb)': 'rate'}, axis=1, \n",
    "                       inplace=True)\n",
    "    genetic_map['start_map'] = np.concatenate([[0], genetic_map.end_map[:-1]])\n",
    "    genetic_map = genetic_map.loc[:, ['chrom_map', 'start_map', 'end_map', 'rate']]\n",
    "    genetic_maps.append(genetic_map)\n",
    "genetic_map = pd.concat(genetic_maps)\n",
    "windows = BedTool('data/reference/hg38.chrom.sizes.bed').window_maker(w=300000, \n",
    "                                                                      g='data/reference/genomefile_hg38.bed')\n",
    "columns = ['chrom', 'start', 'end']\n",
    "columns.extend(genetic_map.columns.values.tolist())\n",
    "columns.append('overlap')\n",
    "rec_windows = windows.intersect(BedTool.from_dataframe(genetic_map), wao=True).to_dataframe(names=columns)\n",
    "rec_windows.rate = np.where(rec_windows.rate == '.', '0', rec_windows.rate)\n",
    "rec_windows.rate = rec_windows.rate.astype(float)\n",
    "rec_windows['rate'] *= rec_windows['overlap']\n",
    "rec_windows = rec_windows.loc[:,['chrom', 'start', 'end', \n",
    "                                 'rate', 'overlap']].groupby(['chrom', 'start', 'end']).sum()\n",
    "rec_windows.rate /= rec_windows.overlap\n",
    "rec_windows.reset_index(inplace=True)\n",
    "rec_windows.fillna(0, inplace=True)\n",
    "low_rec_thresh = np.percentile(rec_windows.rate.values, 33)\n",
    "high_rec_thresh = np.percentile(rec_windows.rate.values, 66)\n",
    "pass_rec_filter = rec_windows.loc[(rec_windows.rate >= low_rec_thresh) & \n",
    "                                  (rec_windows.rate <= high_rec_thresh), ['chrom', 'start', 'end']]\n",
    "pass_rec_filter = BedTool.from_dataframe(pass_rec_filter).merge().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "low_rec_thresh = np.percentile(rec_windows.rate.values, 33)\n",
    "high_rec_thresh = np.percentile(rec_windows.rate.values, 66)\n",
    "\n",
    "ax.hist(rec_windows.rate, bins=100, histtype='step', \n",
    "        weights=np.repeat(1 / rec_windows.shape[0], rec_windows.shape[0]),\n",
    "        cumulative=True)\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_xlabel('Recombination rate (cM/Mb)')\n",
    "ax.axvline(low_rec_thresh, 0, 0.33, ls='--', color='black', label='33th/66th percentile')\n",
    "ax.axvline(high_rec_thresh, 0, 0.66, ls='--', color='black')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rec_thresh * 1e-2 * 1e-6, high_rec_thresh * 1e-2 * 1e-6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdmix_recomb = BedTool.from_dataframe(ibdmix).intersect(BedTool.from_dataframe(pass_rec_filter), \n",
    "                                                             f=1).to_dataframe(names=ibdmix.columns)\n",
    "amounts_recomb = calculate_expected_introgression(admixture_proportions, ibdmix_recomb)\n",
    "\n",
    "\n",
    "(simulations_recomb_masked_ratios, simulations_recomb_masked_ratios_short, \n",
    " simulations_recomb_masked_ratios_medium, simulations_recomb_masked_ratios_long, \n",
    " simulations_recomb_masked_differences, simulations_recomb_masked_differences_short, \n",
    " simulations_recomb_masked_differences_medium, \n",
    " simulations_recomb_masked_differences_long, simulations_recomb_masked_slopes, \n",
    " simulations_recomb_masked_intercepts, simulations_recomb_masked_lengths, \n",
    " simulations_recomb_masked_lods) = load_simulations('simulations_recomb_masked')\n",
    "\n",
    "fig, ax, ax1 = plot_scatter_and_simulated_hist(amounts_recomb, \n",
    "                                               simulations_recomb_masked_differences, \n",
    "                                               color_scatter='Oranges', color_reg='orange', \n",
    "                                               color_sim='darkorange', plot_difference=True, \n",
    "                                               histrange=(-.2, .5))\n",
    "fig.savefig('visualizations/nea_enrichment_masked_recomb.pdf', bbox_inches='tight', dpi=600)\n",
    "fig.savefig('visualizations/nea_enrichment_masked_recomb.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((amounts_recomb['length'] - amounts_recomb['expected_introgression'])) / (2875001522 / 1e6) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### Apply both filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdmix_afr_recomb = BedTool.from_dataframe(ibdmix_masked).intersect(BedTool.from_dataframe(pass_rec_filter), \n",
    "                                                         f=1).to_dataframe(names=ibdmix_masked.columns)\n",
    "amounts_afr_recomb = calculate_expected_introgression(admixture_proportions, ibdmix_afr_recomb)\n",
    "\n",
    "(simulations_afr_recomb_masked_ratios, simulations_afr_recomb_masked_ratios_short, \n",
    " simulations_afr_recomb_masked_ratios_medium, simulations_afr_recomb_masked_ratios_long, \n",
    " simulations_afr_recomb_masked_differences, simulations_afr_recomb_masked_differences_short, \n",
    " simulations_afr_recomb_masked_differences_medium, \n",
    " simulations_afr_recomb_masked_differences_long, simulations_afr_recomb_masked_slopes, \n",
    " simulations_afr_recomb_masked_intercepts, simulations_afr_recomb_masked_lengths, \n",
    " simulations_afr_recomb_masked_lods) = load_simulations('simulations_afr_recomb_masked')\n",
    "\n",
    "fig, ax, ax1 = plot_scatter_and_simulated_hist(amounts_afr_recomb, \n",
    "                                               simulations_afr_recomb_masked_differences, \n",
    "                                               color_scatter='Greens', color_reg='forestgreen', \n",
    "                                               color_sim='forestgreen', plot_difference=True, \n",
    "                                               histrange=(-.2, .5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Explore the segments that are removed by the African mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibdmix_removed = BedTool.from_dataframe(ibdmix).intersect(\n",
    "    BedTool.from_dataframe(ibdmix[ibdmix.super_pop == 'AFR']), \n",
    "    u=True).to_dataframe(names=ibdmix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = rec_windows.columns.tolist()\n",
    "columns.append('n_overlap')\n",
    "rec_afr_mask = BedTool.from_dataframe(rec_windows).intersect(\n",
    "    BedTool.from_dataframe(ibdmix_removed[ibdmix_removed['pop'] == 'AA']), C=True).to_dataframe(names=columns)\n",
    "rec_non_afr_mask = BedTool.from_dataframe(rec_windows).intersect(\n",
    "    BedTool.from_dataframe(ibdmix_masked[ibdmix_masked['pop'] == 'AA']), C=True).to_dataframe(names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(8, 3), sharey=True)\n",
    "\n",
    "ax[0].step(np.concatenate([[ibdmix_removed['length'].min() / 1000], np.sort(ibdmix_removed['length']) / 1000]), \n",
    "        np.arange(0, ibdmix_removed['length'].shape[0] +1) / float(ibdmix_removed['length'].shape[0]), \n",
    "        color='red', label='Segments removed with AFR mask')\n",
    "ax[0].step(np.concatenate([[ibdmix_masked['length'].min() / 1000], np.sort(ibdmix_masked['length']) / 1000]), \n",
    "        np.arange(0, ibdmix_masked['length'].shape[0] +1) / float(ibdmix_masked['length'].shape[0]), \n",
    "        color='purple', label='Segments retained')\n",
    "ax[0].set_xlabel('Segment length in kb')\n",
    "ax[0].set_ylabel(\"CDF\")\n",
    "ax[0].set_xlim([50, 250])\n",
    "_, pval = mannwhitneyu(ibdmix_removed['length'], ibdmix_masked['length'])\n",
    "if pval <= 10e-6:\n",
    "    ax[0].annotate(r'$p \\leq 10^{-6}$', (1, 1), (0.5, 0.05), \n",
    "               xycoords='axes fraction')\n",
    "else:\n",
    "    ax[0].annotate('P = {:.2e}'.format(pval), (1, 1), (0.5, 0.05), \n",
    "               xycoords='axes fraction')\n",
    "\n",
    "\n",
    "\n",
    "ax[1].step(np.concatenate([[ibdmix_removed['LOD'].min()], np.sort(ibdmix_removed['LOD'])]), \n",
    "        np.arange(0, ibdmix_removed['LOD'].shape[0] +1) / float(ibdmix_removed['LOD'].shape[0]), \n",
    "        color='red', label='Segments removed with AFR mask')\n",
    "ax[1].step(np.concatenate([[ibdmix_masked['LOD'].min()], np.sort(ibdmix_masked['LOD'])]), \n",
    "        np.arange(0, ibdmix_masked['LOD'].shape[0] +1) / float(ibdmix_masked['LOD'].shape[0]), \n",
    "        color='purple', label='Segments retained')\n",
    "ax[1].legend(bbox_to_anchor=(0.5, -.2), loc='upper center', ncol=2)\n",
    "ax[1].set_xlabel('LOD score')\n",
    "ax[1].set_xlim(4, 200)\n",
    "_, pval = mannwhitneyu(ibdmix_removed['LOD'], ibdmix_masked['LOD'])\n",
    "if pval <= 10e-6:\n",
    "    ax[1].annotate(r'$p \\leq 10^{-6}$', (1, 1), (0.5, 0.05), \n",
    "               xycoords='axes fraction')\n",
    "else:\n",
    "    ax[1].annotate('P = {:.2e}'.format(pval), (1, 1), (0.5, 0.05), \n",
    "               xycoords='axes fraction')\n",
    "\n",
    "ax[2].step(np.concatenate([[rec_afr_mask.rate.values.min()], np.sort(rec_afr_mask.rate.values)]), \n",
    "        np.concatenate([[0], (np.cumsum(rec_afr_mask.n_overlap.values[np.argsort(rec_afr_mask.rate)]) / \n",
    "                              rec_afr_mask.n_overlap.values.sum())]), \n",
    "        color='red', label='Segments removed with AFR mask')\n",
    "# ax.hist(rec_afr_mask.rate, bins=100, color='red', cumulative=True, histtype='step', \n",
    "#         weights=rec_afr_mask.n_overlap.values / rec_afr_mask.n_overlap.values.sum(),\n",
    "#         label='Segments removed with AFR mask',range=(0, 5))\n",
    "\n",
    "ax[2].step(np.concatenate([[rec_non_afr_mask.rate.values.min()], np.sort(rec_non_afr_mask.rate.values)]), \n",
    "        np.concatenate([[0], (np.cumsum(rec_non_afr_mask.n_overlap.values[np.argsort(rec_non_afr_mask.rate)]) / \n",
    "                              rec_non_afr_mask.n_overlap.values.sum())]), \n",
    "        color='purple', label='Segments retained')\n",
    "# ax.hist(rec_non_afr_mask.rate, bins=100, color='blue', cumulative=True, histtype='step', \n",
    "#         weights=rec_non_afr_mask.n_overlap.values / rec_non_afr_mask.n_overlap.values.sum(), \n",
    "#         label='Segments retained', range=(0, 5))\n",
    "# ax.legend(bbox_to_anchor=(0.5, -.12), loc='upper center', ncol=2)\n",
    "ax[2].set_xlabel('Recombination rate (cM/Mb)')\n",
    "_, pval = mannwhitneyu(rec_afr_mask.rate.values * rec_afr_mask.n_overlap.values / rec_afr_mask.n_overlap.values.sum(), \n",
    "                       rec_non_afr_mask.rate.values * rec_non_afr_mask.n_overlap.values / rec_non_afr_mask.n_overlap.values.sum())\n",
    "if pval <= 10e-6:\n",
    "    ax[2].annotate(r'$p \\leq 10^{-6}$', (1, 1), (0.5, 0.05), \n",
    "               xycoords='axes fraction')\n",
    "else:\n",
    "    ax[2].annotate('P = {:.2e}'.format(pval), (1, 1), (0.5, 0.05), \n",
    "               xycoords='axes fraction')\n",
    "ax[0].annotate(\"A\", (1, 1), (-0.3, 0.92), xycoords='axes fraction', fontsize=14, fontweight='bold')\n",
    "ax[1].annotate(\"B\", (1, 1), (-0.15, 0.92), xycoords='axes fraction', fontsize=14, fontweight='bold')\n",
    "ax[2].annotate(\"C\", (1, 1), (-0.15, 0.92), xycoords='axes fraction', fontsize=14, fontweight='bold')\n",
    "fig.savefig('visualizations/segments_afr_mask.pdf', dpi=600, bbox_inches='tight')\n",
    "fig.savefig('visualizations/segments_afr_mask.png', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitneyu(ibdmix_removed['length'], ibdmix_masked['length'], alternative='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### Compare introgression frequencies in different Eurpean reference populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "def get_introgression_freq(df, n_indv, cols):\n",
    "    df_freq = BedTool('data/reference/hg38_windowed_w_50000_s_10000.bed').intersect(\n",
    "        BedTool.from_dataframe(df), wo=True).to_dataframe(names=cols)\n",
    "    df_freq = df_freq.loc[:, ['chrom', 'start', \n",
    "                              'end', 'overlap']].groupby(['chrom', 'start', 'end']).sum() / 50000 / n_indv\n",
    "#     df_freq += 2\n",
    "#     df_freq /= (n_indv + 4)\n",
    "    df_freq.rename({'overlap': 'freq'}, axis=1, inplace=True)\n",
    "    return df_freq\n",
    "\n",
    "# ibdmix_aou_eur = ibdmix[ibdmix['pop'] == 'AOUEUR']\n",
    "# ibdmix_1kgp_eur = ibdmix[(ibdmix['pop'] != 'PEGS') & \n",
    "#                          (ibdmix['pop'] != 'AOUEUR') &\n",
    "#                          (ibdmix['super_pop'] == 'EUR')]\n",
    "\n",
    "ibdmix_masked_aou_eur = ibdmix_masked[ibdmix_masked['pop'] == 'AOU-EUR']\n",
    "ibdmix_masked_1kgp_eur = ibdmix_masked[(ibdmix_masked['pop'] != 'PEGS-EUR') & \n",
    "                                       (ibdmix_masked['pop'] != 'AOU-EUR') &\n",
    "                                       (ibdmix_masked['super_pop'] == 'EUR')]\n",
    "\n",
    "\n",
    "n_indv_aou = 10000\n",
    "n_indv_1kgp = 503\n",
    "# n_indv_pegs = 3341\n",
    "columns = ['chrom', 'start', 'end']\n",
    "columns.extend([col if col != 'chrom' and col != 'start' and col != 'end' else col +'_r' \n",
    "                for col in ibdmix_masked.columns])\n",
    "columns.append('overlap')\n",
    "\n",
    "introgression_freq_aou = get_introgression_freq(ibdmix_masked_aou_eur, n_indv_aou, columns)\n",
    "introgression_freq_1kgp = get_introgression_freq(ibdmix_masked_1kgp_eur, n_indv_1kgp, columns)\n",
    "\n",
    "introgression_freq_aou_1kgp = introgression_freq_aou.join(introgression_freq_1kgp, \n",
    "                                                          lsuffix='_aou', rsuffix='_1kgp',\n",
    "                                                          how='outer').fillna(0.0)\n",
    "\n",
    "(slope_aou_1kgp, intercept_aou_1kgp, rval_aou_1kgp, pval_aou_1kgp, x_model_aou_1kgp, y_model_aou_1kgp,\n",
    " ci_aou_1kgp, pi_aou_1kgp) = linear_regression(introgression_freq_aou_1kgp.freq_aou.values,\n",
    "                                               introgression_freq_aou_1kgp.freq_1kgp.values,\n",
    "                                               full_range=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "\n",
    "\n",
    "ax.scatter(introgression_freq_aou_1kgp.freq_aou, introgression_freq_aou_1kgp.freq_1kgp, s=2)\n",
    "ax.plot([0, 1], [0, 1], ls='--', color='black', transform=ax.transAxes)\n",
    "ax.set_xlabel('AOU-EUR (10,000)')\n",
    "ax.set_ylabel('1KGP-EUR (503)', labelpad=10)\n",
    "ax.set_aspect('equal')\n",
    "if pval_aou_1kgp < 10e-6:\n",
    "    pvalue_string = r'$p \\leq 10^{-6}$; '\n",
    "else:\n",
    "    pvalue_string = r'p={:.2e}; '.format(pval_aou_1kgp)\n",
    "ax.annotate(\"m={:.2f}; \".format(slope_aou_1kgp) + pvalue_string + \n",
    "                  r'$r=$' + \"{:.2f}\".format(rval_aou_1kgp), \n",
    "                  (1, 1), (0.02, 0.92), fontsize=8, xycoords='axes fraction')\n",
    "\n",
    "\n",
    "\n",
    "fig.savefig('visualizations/introgression_frequencies_1kgp_aou_50kb.pdf', dpi=600, bbox_inches='tight')\n",
    "fig.savefig('visualizations/introgression_frequencies_1kgp_aou_50kb.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.legend_handler import HandlerTuple\n",
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "def get_min_sel_coeff(low, high):\n",
    "    sel_coeff = np.stack([low, high])\n",
    "    return np.where((sel_coeff[0, : ] < 0) & (sel_coeff[1, :] > 0), 0, np.abs(sel_coeff).min(axis=0))\n",
    "\n",
    "\n",
    "def find_significant_segments(df, enriched=False, depleted=False, min_length=90000, windowsize=50000, \n",
    "                              stride=10000):\n",
    "    if enriched:\n",
    "        df = df[df.freq > df.expectations].copy()\n",
    "    elif depleted:\n",
    "        df = df[df.freq < df.expectations].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    if windowsize > stride:\n",
    "        min_windows = int((min_length - windowsize) / stride + 1)\n",
    "    elif windowsize == stride:\n",
    "        min_windows = int(min_length / stride)\n",
    "    print(min_windows)\n",
    "    idx_start = 0\n",
    "    idx_end = 1\n",
    "    differences = np.diff(df.start.values)\n",
    "    to_keep = []\n",
    "    for diff in differences:\n",
    "        if diff == stride:\n",
    "            idx_end += 1\n",
    "        elif diff != stride and idx_end - idx_start >= min_windows:\n",
    "            to_keep.append(np.arange(idx_start, idx_end + 1))\n",
    "            idx_start = idx_end\n",
    "            idx_end += 1\n",
    "            \n",
    "        else:\n",
    "            idx_start = idx_end\n",
    "            idx_end += 1\n",
    "            \n",
    "    if idx_end - idx_start >= min_windows:\n",
    "        to_keep.append(np.arange(idx_start, idx_end))\n",
    "    if len(to_keep) > 0 and df.shape[0] > 0:\n",
    "        to_keep = np.concatenate(to_keep)\n",
    "        # need to trait pvalues differently\n",
    "        columns = np.where((df.columns.values != 'probabilities') & \n",
    "                           (df.columns.values != 'corrected'))[0][3:] + 1\n",
    "        merged = BedTool.from_dataframe(df.iloc[to_keep]).merge(c=columns.tolist(),\n",
    "                                                                o='mean',\n",
    "                                                                header=True,\n",
    "                                                                d=50000)\n",
    "        df.drop(['probabilities', 'corrected'], axis=1, inplace=True)\n",
    "        merged = merged.to_dataframe(names=df.columns)\n",
    "    else:\n",
    "        merged = pd.DataFrame(columns=df.columns)\n",
    "    return merged\n",
    "\n",
    "\n",
    "introgression_freq_filtered_fname = 'results50kb_wo_PEGS/ibdmix_Vindija33.19/ibdmix_results_masked_denisovan_combined_50kb_4.0LOD_afr_masked_coverage_per_individual_and_per_window50000_s_10000_pvalues.bed'\n",
    "introgression_freq_filtered = pd.read_csv(introgression_freq_filtered_fname, sep='\\t', header=0)\n",
    "n_indv = ibdmix.loc[ibdmix['pop'] == 'AA', 'IID'].unique().shape[0]\n",
    "introgression_freq_filtered.freq /= n_indv\n",
    "introgression_freq_filtered.freq_updated /= n_indv\n",
    "introgression_freq_filtered.expectations /= n_indv\n",
    "introgression_freq_filtered.sel_coeff = np.nan_to_num(introgression_freq_filtered.sel_coeff, \n",
    "                                                      posinf=0.3, neginf=-0.3)\n",
    "# introgression_freq_filtered['u'] = (np.abs(introgression_freq_filtered.freq_updated.values - \n",
    "#                                            introgression_freq_filtered.expectations.values) * \n",
    "#                                     introgression_freq_filtered.loc[:, ['freq_updated', \n",
    "#                                                                         'expectations']].min(axis=1))\n",
    "# introgression_freq_filtered['min_sel_coeff'] = get_min_sel_coeff(introgression_freq_filtered.sel_coeff_low.values,\n",
    "#                                                                  introgression_freq_filtered.sel_coeff_high.values)\n",
    "# introgression_freq_filtered = BedTool.from_dataframe(introgression_freq_filtered).intersect(\n",
    "#     BedTool.from_dataframe(pass_rec_filter), \n",
    "#     f=1).to_dataframe(names=introgression_freq_filtered.columns)\n",
    "# introgression_freq_filtered.corrected = introgression_freq_filtered.probabilities * introgression_freq_filtered.shape[0]\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "gs = fig.add_gridspec(46, 2, width_ratios=[0.5, 0.5], wspace=0.3)\n",
    "ax0 = fig.add_subplot(gs[:, 0])\n",
    "ax1 = fig.add_subplot(gs[3:43, 1])\n",
    "# ax2 = fig.add_subplot(gs[1, :])\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.4)\n",
    "\n",
    "\n",
    "sd_drift = lambda x: np.sqrt(x * (1-x) * (1 - np.exp(-15 / 30000)))\n",
    "lower_bound = t.ppf(0.025 / introgression_freq_filtered.shape[0], 30780, \n",
    "                   loc=introgression_freq_filtered.expectations.values,\n",
    "                    scale=sd_drift(introgression_freq_filtered.expectations.values))\n",
    "lower_bound = np.nan_to_num(np.where(lower_bound < 0, 0, lower_bound))\n",
    "upper_bound = t.ppf(1 - 0.025 / introgression_freq_filtered.shape[0], 30780, \n",
    "                    loc=introgression_freq_filtered.expectations.values, \n",
    "                    scale=sd_drift(introgression_freq_filtered.expectations.values))\n",
    "upper_bound = np.nan_to_num(upper_bound)\n",
    "\n",
    "introgression_freq_filtered['drift_lower'] = lower_bound\n",
    "introgression_freq_filtered['drift_upper'] = upper_bound\n",
    "\n",
    "significant = introgression_freq_filtered[(introgression_freq_filtered.corrected < 0.05) &\n",
    "                                          ((introgression_freq_filtered.freq_updated > \n",
    "                                            introgression_freq_filtered.drift_upper) | \n",
    "                                           (introgression_freq_filtered.freq_updated < \n",
    "                                            introgression_freq_filtered.drift_lower))]\n",
    "non_significant = introgression_freq_filtered[(introgression_freq_filtered.corrected >= 0.05) |\n",
    "                                              ((introgression_freq_filtered.freq_updated >= \n",
    "                                                introgression_freq_filtered.drift_lower) &\n",
    "                                               (introgression_freq_filtered.freq_updated <= \n",
    "                                                introgression_freq_filtered.drift_upper))]\n",
    "lower_bound = t.ppf(0.025 / introgression_freq_filtered.shape[0], 30780, \n",
    "                   loc=np.arange(0, 0.15, 0.0001), \n",
    "                    scale=sd_drift(np.arange(0, 0.15, 0.0001)))\n",
    "lower_bound = np.nan_to_num(np.where(lower_bound < 0, 0, lower_bound))\n",
    "upper_bound = t.ppf(1 - 0.025 / introgression_freq_filtered.shape[0], 30780, \n",
    "                    loc=np.arange(0, 0.15, 0.0001), \n",
    "                    scale=sd_drift(np.arange(0, 0.15, 0.0001)))\n",
    "upper_bound = np.nan_to_num(upper_bound)\n",
    "\n",
    "ax0.plot(np.arange(0, 0.15, 0.0001), upper_bound, ls='--', color='grey')\n",
    "ax0.plot(np.arange(0, 0.15, 0.0001), lower_bound, ls='--', color='grey')\n",
    "\n",
    "ax0.scatter(non_significant.expectations.values, non_significant.freq_updated.values, color='gray', \n",
    "           s=2, label='p' + r'$\\geq$' + '{:.2e}'.format(0.05/introgression_freq_filtered.shape[0]))\n",
    "ax0.scatter(significant.loc[significant.freq_updated > significant.expectations, 'expectations'].values, \n",
    "           significant.loc[significant.freq_updated > significant.expectations, 'freq'].values, s=2, c='blue', \n",
    "           label='p < {:.2e}'.format(0.05/introgression_freq_filtered.shape[0]), alpha=0.1)\n",
    "ax0.scatter(significant.loc[significant.freq_updated < significant.expectations, 'expectations'].values, \n",
    "           significant.loc[significant.freq_updated < significant.expectations, 'freq'].values, s=2, c='red', \n",
    "           label='p < {:.2e}'.format(0.05/introgression_freq_filtered.shape[0]), alpha=0.1)\n",
    "\n",
    "ax0.plot([0, 1], [0, 1], ls='--', c='black', label=f'y=x')\n",
    "\n",
    "\n",
    "ax0.plot(np.arange(0, 0.15, 0.0001), upper_bound, ls='--', color='grey')\n",
    "ax0.plot(np.arange(0, 0.15, 0.0001), lower_bound, ls='--', color='grey')\n",
    "\n",
    "\n",
    "handles = [Line2D([0], [0], marker='o', markersize=2, color='gray', ls='',\n",
    "                  label='P' + r'$\\geq$' + '{:.2e}'.format(0.05/introgression_freq_filtered.shape[0])),\n",
    "           (Line2D([0], [0], marker='o', markersize=2, color='red', ls=''),\n",
    "            Line2D([0], [0], marker='o', markersize=2, color='blue', ls=''))]\n",
    "ax0.legend(handles, [#'P' + r'$\\geq$' + '{:.2e}'.format(0.05/introgression_freq_filtered.shape[0]),\n",
    "                     #'P < {:.2e}'.format(0.05/introgression_freq_filtered.shape[0]),\n",
    "                     'Not significant',\n",
    "                     'Significantly depleted/enriched'], \n",
    "           bbox_to_anchor=(0.5, -.29), loc='center', ncol=3, fontsize=9, markerscale=2,\n",
    "           handletextpad=0.4, columnspacing=1, handlelength=1.5, \n",
    "           handler_map={tuple: HandlerTuple(ndivide=None)})\n",
    "ax0.set_xlabel(\"Exp. introgression frequency (50 kb)\", fontsize=10)\n",
    "ax0.set_ylabel(\"Obs. introgression frequency (50 kb)\", fontsize=10)\n",
    "\n",
    "\n",
    "ax0.set_aspect('equal')\n",
    "ax0.set_xlim([0.0, 0.13])\n",
    "ax0.set_ylim([0.0, 0.13])\n",
    "inset = ax0.inset_axes([0.58, 0.03, 0.38, 0.38], xlim=(0, 0.04), ylim=(0, 0.04),\n",
    "                         yticklabels=[], xticklabels=[], xticks=np.arange(0, 0.05, 0.01),\n",
    "                         yticks=np.arange(0, 0.05, 0.01))\n",
    "inset.scatter(non_significant.expectations.values, non_significant.freq_updated.values, color='gray', s=2)\n",
    "inset.scatter(significant.loc[significant.freq_updated > significant.expectations, 'expectations'].values, \n",
    "              significant.loc[significant.freq_updated > significant.expectations, 'freq'].values, s=2, c='blue', \n",
    "              label='p < {:.2e}'.format(0.05/introgression_freq_filtered.shape[0]), alpha=0.1)\n",
    "inset.scatter(significant.loc[significant.freq_updated < significant.expectations, 'expectations'].values, \n",
    "              significant.loc[significant.freq_updated < significant.expectations, 'freq'].values, s=2, c='red', \n",
    "              label='p < {:.2e}'.format(0.05/introgression_freq_filtered.shape[0]), alpha=0.1)\n",
    "inset.plot([0, 1], [0, 1], ls='--', c='black')\n",
    "inset.plot(np.arange(0, 0.15, 0.0001), upper_bound, ls='--', color='grey')\n",
    "inset.plot(np.arange(0, 0.15, 0.0001), lower_bound, ls='--', color='grey')\n",
    "\n",
    "\n",
    "ax0.indicate_inset_zoom(inset, edgecolor=\"black\")\n",
    "simulations = load_npz('simulations_freq_differences_50kb_windows.npz')\n",
    "for i, diff in enumerate(simulations):\n",
    "    ax1.hist(diff, bins=500,\n",
    "             color='grey', histtype='step', weights = np.repeat(1 / diff.shape[0], diff.shape[0]),\n",
    "             range=(-0.01, 0.01), alpha=0.4)\n",
    "ax1.hist(introgression_freq_filtered.freq_updated - introgression_freq_filtered.expectations, \n",
    "         bins=500,\n",
    "         color='red', histtype='step', weights = np.repeat(1 / introgression_freq_filtered.shape[0], \n",
    "                                                          introgression_freq_filtered.shape[0]),\n",
    "         range=(-0.01, 0.01), label='Admixed individuals')\n",
    "ax1.axvline(0.0, ls='--', color='black')\n",
    "ax1.set_ylabel(\"Density\", fontsize=10)\n",
    "ax1.set_xlabel('Obs. - Exp. introgression frequency (50 kb)', fontsize=10)\n",
    "handles = [Line2D([0], [0], ls='-', color='grey', label='Simulations'),\n",
    "           Line2D([0], [0], ls='-', color='red', label='AOU-Admixed')]\n",
    "ax1.legend(handles=handles, bbox_to_anchor=(0.5, -.29), loc='center', ncol=2, markerscale=2,\n",
    "           handletextpad=0.4, columnspacing=1, handlelength=1.5, fontsize=9)\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "ax0.annotate(\"A\", (1, 1), (-0.35, 0.9), fontsize=16, fontweight='bold', xycoords='axes fraction')\n",
    "ax1.annotate(\"B\", (1, 1), (-0.25, 0.9), fontsize=16, fontweight='bold', xycoords='axes fraction')\n",
    "fig.savefig(\"visualizations/nea_enrichment_50kb.pdf\", bbox_inches='tight', dpi=600)\n",
    "fig.savefig(\"visualizations/nea_enrichment_50kb.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression(introgression_freq_filtered.expectations, introgression_freq_filtered.freq_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "racimo = pd.read_excel('TableS3_Racimo2017.xlsx')\n",
    "columns = ['chrom', 'start', 'end']\n",
    "columns.extend(racimo.columns.values.tolist())\n",
    "racimo['chrom'] = [region.split(':')[0] for region in racimo['Chr:Start-End'].values]\n",
    "racimo['start'] = [int(region.split(':')[1].split('-')[0]) for region in racimo['Chr:Start-End'].values]\n",
    "racimo['end'] = [int(region.split(':')[1].split('-')[1]) for region in racimo['Chr:Start-End'].values]\n",
    "racimo = racimo.loc[:, columns].sort_values(['chrom', 'start'])\n",
    "racimo = racimo[((racimo.Mode == 'eurasia') & ((racimo.Archaic_pop == 'Both') | (racimo.Archaic_pop == 'Nea'))) | \n",
    "                ((racimo.Mode == 'continents') & (racimo.Modern_pop == 'EUR') & \n",
    "                 ((racimo.Archaic_pop == 'Both') | (racimo.Archaic_pop == 'Nea'))) | \n",
    "       ((racimo.Mode == 'continentsB') & (racimo.Modern_pop == 'EUR') & ((racimo.Archaic_pop == 'Both') | \n",
    "                                                                         (racimo.Archaic_pop == 'Nea'))) |\n",
    "       ((racimo.Mode == 'populationsB') & np.isin(racimo.Modern_pop.values, ['GBR', 'TSI', 'IBS', 'FIN', 'CEU']) & \n",
    "        ((racimo.Archaic_pop == 'Both') | (racimo.Archaic_pop == 'Nea')))]\n",
    "racimo.loc[:, ['chrom', 'start', 'end']].to_csv('TableS3_Racimo2017_EUR_hg19.bed', sep='\\t', header=False, index=False)\n",
    "# !CrossMap.py bed --chromid l data/reference/hg19ToHg38.over.chain.gz TableS3_Racimo2017_EUR_hg19.bed TableS3_Racimo2017_EUR_hg38.bed\n",
    "racimo = pd.read_csv('TableS3_Racimo2017_EUR_hg38.bed', sep='\\t', names=['chrom', 'start', 'end'])\n",
    "introgression_freq = pd.read_csv('results50kb_wo_PEGS/ibdmix_Vindija33.19/ibdmix_results_masked_denisovan_combined_50kb_4.0LOD_afr_masked_coverage_per_individual_and_per_window50000_s_10000_expectations.bed',\n",
    "                                 sep='\\t')\n",
    "introgression_freq_filtered = pd.read_csv(introgression_freq_filtered_fname, sep='\\t', header=0)\n",
    "columns = ['chrom_l', 'start_l', 'end_l']\n",
    "columns.extend(introgression_freq.columns.values.tolist())\n",
    "# columns.extend(introgression_freq_filtered.columns.values.tolist())\n",
    "columns.append('overlap')\n",
    "racimo = BedTool.from_dataframe(racimo).intersect(BedTool.from_dataframe(introgression_freq), \n",
    "# racimo = BedTool.from_dataframe(racimo).intersect(BedTool.from_dataframe(introgression_freq_filtered), \n",
    "                                                  wao=True).to_dataframe(names=columns)\n",
    "racimo = racimo[racimo.overlap > 0].drop(['chrom', 'start', 'end'], axis=1)\n",
    "racimo.freq = racimo.freq.astype(float)\n",
    "racimo.freq_updated = racimo.freq_updated.astype(float)\n",
    "racimo.expectations = racimo.expectations.astype(float)\n",
    "racimo.freq_eur = racimo.freq_eur.astype(float)\n",
    "racimo.freq_eas = racimo.freq_eas.astype(float)\n",
    "racimo.freq_la_afr = racimo.freq_la_afr.astype(int)\n",
    "racimo.freq_la_eur = racimo.freq_la_eur.astype(int)\n",
    "racimo.freq_la_eas = racimo.freq_la_eas.astype(int)\n",
    "# racimo.probabilities = racimo.probabilities.astype(float)\n",
    "# racimo.corrected = racimo.corrected.astype(float)\n",
    "# racimo.sel_coeff = racimo.sel_coeff.astype(float)\n",
    "# racimo.drift_lower = racimo.drift_lower.astype(float)\n",
    "# racimo.drift_upper = racimo.drift_upper.astype(float)\n",
    "\n",
    "\n",
    "\n",
    "racimo.set_index(['chrom_l', 'start_l', 'end_l'], inplace=True)\n",
    "racimo.iloc[:, :-1] *= racimo.iloc[:, -1].values[:, np.newaxis] \n",
    "\n",
    "racimo = racimo.groupby(['chrom_l', 'start_l', 'end_l']).sum().iloc[:, :-1] / racimo.groupby(['chrom_l', 'start_l', 'end_l']).sum().iloc[:, -1].values[:, np.newaxis]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(racimo.expectations / n_indv, racimo.freq_updated / n_indv, color='black', s=8)\n",
    "ax.set_aspect('equal')\n",
    "ax.plot([0, 1], [0, 1], ls='--', color='black')\n",
    "ax.set_xlim([0, 0.07])\n",
    "ax.set_ylim([0, 0.07])\n",
    "ax.set_xlabel('Expected introgression frequency (50 kb)')\n",
    "ax.set_ylabel('Observed introgression frequency (50 kb)')\n",
    "\n",
    "sd_drift = lambda x: np.sqrt(x * (1-x) * (1 - np.exp(-15 / 30000)))\n",
    "lower_bound = t.ppf(0.025 / introgression_freq_filtered.shape[0], 30780, \n",
    "                   loc=racimo.expectations.values / n_indv,\n",
    "                    scale=sd_drift(racimo.expectations.values / n_indv))\n",
    "lower_bound = np.nan_to_num(np.where(lower_bound < 0, 0, lower_bound))\n",
    "upper_bound = t.ppf(1 - 0.025 / introgression_freq_filtered.shape[0], 30780, \n",
    "                    loc=racimo.expectations.values / n_indv, \n",
    "                    scale=sd_drift(racimo.expectations.values / n_indv))\n",
    "upper_bound = np.nan_to_num(upper_bound)\n",
    "\n",
    "racimo['drift_lower'] = lower_bound\n",
    "racimo['drift_upper'] = upper_bound\n",
    "\n",
    "lower_bound = t.ppf(0.025 / introgression_freq_filtered.shape[0], 30780, \n",
    "                   loc=np.arange(0, 0.15, 0.0001), \n",
    "                    scale=sd_drift(np.arange(0, 0.15, 0.0001)))\n",
    "lower_bound = np.nan_to_num(np.where(lower_bound < 0, 0, lower_bound))\n",
    "upper_bound = t.ppf(1 - 0.025 / introgression_freq_filtered.shape[0], 30780, \n",
    "                    loc=np.arange(0, 0.15, 0.0001), \n",
    "                    scale=sd_drift(np.arange(0, 0.15, 0.0001)))\n",
    "upper_bound = np.nan_to_num(upper_bound)\n",
    "\n",
    "ax.plot(np.arange(0, 0.15, 0.0001), upper_bound, ls='--', color='grey')\n",
    "ax.plot(np.arange(0, 0.15, 0.0001), lower_bound, ls='--', color='grey')\n",
    "\n",
    "\n",
    "fig.savefig('visualizations/comparison_racimo_eur.pdf', bbox_inches='tight', dpi=600)\n",
    "fig.savefig('visualizations/comparison_racimo_eur.png', bbox_inches='tight', dpi=600)\n",
    "racimo[((racimo.freq_updated / n_indv > racimo.drift_upper) | \n",
    "        (racimo.freq_updated / n_indv < racimo.drift_lower))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(introgression_freq.freq_updated / introgression_freq.expectations, bins=100, range=(0, 20), \n",
    "#         weights=np.repeat(1 / introgression_freq.shape[0], introgression_freq.shape[0]), histtype='step')\n",
    "# ax.hist(racimo.freq_updated / racimo.expectations, bins=100, range=(0, 20), color='orange', \n",
    "#         weights=np.repeat(1 / racimo.shape[0], racimo.shape[0]), histtype='step')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "racimo.freq_updated / racimo.expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "racimo[racimo.overlap > 0].drop(['chrom', 'start', 'end'], axis=1).groupby(['chrom_l', 'start_l', 'end_l']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "racimo[np.isin(racimo.Modern_pop.values, ['GBR', 'TSI', 'IBS', 'FIN', 'CEU'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_introgression_freq_filtered = pd.read_csv('simulated_introgression_freq_filtered.bed', \n",
    "                                                    sep='\\t', header=0)\n",
    "\n",
    "import seaborn as sns\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "import scipy.ndimage as ndimage\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def get_peaks(residuals):\n",
    "    residuals = ndimage.gaussian_filter(residuals, sigma=2, radius=6)\n",
    "    residuals = np.where(residuals < 1e-6, 0, residuals)\n",
    "    distance = ndimage.distance_transform_edt(residuals)\n",
    "    coords = peak_local_max(distance, footprint=np.ones((6, 6)), threshold_abs=1e-6)\n",
    "    mask = np.zeros(residuals.shape, dtype=bool)\n",
    "    mask[tuple(coords.T)] = True\n",
    "    markers, _ = ndimage.label(mask)\n",
    "    labels = watershed(-distance, markers, mask=residuals)\n",
    "    return labels\n",
    "\n",
    "def extract_bins_in_watershed(df, bins, peaks):\n",
    "    significant = []\n",
    "    bin_size = np.diff(bins)[0]\n",
    "    for label in np.unique(peaks):\n",
    "        if label == 0:\n",
    "            continue\n",
    "        bins_x = bins[np.where(peaks == label)[1]]\n",
    "        bins_y = bins[np.where(peaks == label)[0]]\n",
    "        for x, y in zip(bins_x, bins_y):\n",
    "            significant.append(df[(df.expectations >= x) &\n",
    "                                  (df.expectations < x + bin_size) &\n",
    "                                  (df.freq_updated >= y) &\n",
    "                                  (df.freq_updated < y + bin_size)])\n",
    "    return pd.concat(significant).sort_values(['chrom', 'start'])\n",
    "\n",
    "def match_residuals_to_windows(df, bins, residuals):\n",
    "    residuals = ndimage.gaussian_filter(residuals, sigma=2, radius=6)\n",
    "    residuals = np.where(residuals < 1e-6, 0, residuals)\n",
    "    distance = ndimage.distance_transform_edt(residuals)\n",
    "    distance = distance[np.digitize(df.freq_updated, bins[:-1], right=True) - 1, \n",
    "                        np.digitize(df.expectations, bins[:-1], right=True) - 1]\n",
    "    return distance\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "gs = fig.add_gridspec(2, 14, wspace=0.4, hspace=0.3)\n",
    "ax0 = fig.add_subplot(gs[0, 0:6])\n",
    "ax1 = fig.add_subplot(gs[0, 8:])\n",
    "ax2 = fig.add_subplot(gs[1, 4:10])\n",
    "# ax3 = fig.add_subplot(gs[1, :])\n",
    "plt.subplots_adjust(wspace=0.75)\n",
    "\n",
    "\n",
    "nbins = 50\n",
    "bins = np.linspace(0, 0.1, nbins)\n",
    "# get heatmaps of expectations vs observations\n",
    "heatmap, _, _ = np.histogram2d(introgression_freq_filtered.expectations, \n",
    "                               introgression_freq_filtered.freq_updated, bins=bins)\n",
    "\n",
    "heatmap_simulated, _, _ = np.histogram2d(simulated_introgression_freq_filtered.expectations, \n",
    "                                         simulated_introgression_freq_filtered.freq_updated, \n",
    "                                         bins=bins)\n",
    "#plot heat maps\n",
    "divider = make_axes_locatable(ax0)\n",
    "cax0 = divider.append_axes('right', size='5%', pad=0.05)\n",
    "im0 = ax0.imshow(heatmap.T / introgression_freq_filtered.shape[0], \n",
    "                norm=LogNorm(),\n",
    "                origin='lower', cmap='plasma_r')\n",
    "cbar0 = fig.colorbar(im0, cax=cax0, orientation='vertical')\n",
    "cbar0.set_label(\"Density\", fontsize=9)\n",
    "# for t in cbar0.ax.get_yticklabels():\n",
    "#      t.set_fontsize(8)\n",
    "\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax1 = divider.append_axes('right', size='5%', pad=0.05)\n",
    "im1 = ax1.imshow(heatmap_simulated.T / simulated_introgression_freq_filtered.shape[0], \n",
    "                 norm=LogNorm(), origin='lower', cmap='plasma_r')\n",
    "cbar1 = fig.colorbar(im1, cax=cax1, orientation='vertical')\n",
    "cbar1.set_label(\"Density\", fontsize=9)\n",
    "# for t in cbar1.ax.get_yticklabels():\n",
    "#      t.set_fontsize(8)\n",
    "\n",
    "\n",
    "# calculate residuals\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax2 = divider.append_axes('right', size='5%', pad=0.05)\n",
    "residuals = ((heatmap.T / introgression_freq_filtered.shape[0]) -\n",
    "             (heatmap_simulated.T / simulated_introgression_freq_filtered.shape[0]))\n",
    "# find watersheds\n",
    "peaks = get_peaks(residuals)\n",
    "introgression_freq_filtered['residuals'] = match_residuals_to_windows(introgression_freq_filtered, bins, \n",
    "                                                                      residuals)\n",
    "# residuals = np.where(residuals < 0, 0, residuals)\n",
    "# residuals = np.interp(residuals, (residuals.min(), residuals.max()), (0, 10))\n",
    "# residuals = np.nan_to_num(residuals, 0)\n",
    "im2 = ax2.imshow(np.where(residuals < 1e-6, 0, residuals), norm=LogNorm(), \n",
    "                 origin='lower', cmap='plasma_r')\n",
    "cbar2 = fig.colorbar(im2, cax=cax2, orientation='vertical')\n",
    "cbar2.set_label(\"Residuals\", fontsize=9)\n",
    "# for t in cbar2.ax.get_yticklabels():\n",
    "#      t.set_fontsize(9)\n",
    "        \n",
    "### THIS PART IS NOT GENERAL FOR OTHER CASES, I'M JUST MERGING PEAKS HERE TO GET A CLEANER FIGURE\n",
    "peaks = np.where((peaks > 0) & (peaks <= 3), 1, peaks)\n",
    "peaks = np.where((peaks > 3), 2, peaks)\n",
    "\n",
    "for label in np.unique(peaks):\n",
    "    if label != 0:\n",
    "        ellipse = Ellipse(((np.where(peaks == label)[1].max() + np.where(peaks == label)[1].min()) / 2,\n",
    "                           (np.where(peaks == label)[0].max() + np.where(peaks == label)[0].min()) /2), \n",
    "                          width=(np.where(peaks == label)[1].max() + np.where(peaks == label)[1].min()) / 2, \n",
    "                          height=(np.where(peaks == label)[0].max() + np.where(peaks == label)[0].min()) /2,\n",
    "                          fc='None', edgecolor='black')\n",
    "        ax2.add_patch(ellipse)\n",
    "\n",
    "ax0.plot([0, 1], [0, 1], ls='--', c='black', transform=ax0.transAxes)\n",
    "ax1.plot([0, 1], [0, 1], ls='--', c='black', transform=ax1.transAxes)\n",
    "ax2.plot([0, 1], [0, 1], ls='--', c='black', transform=ax2.transAxes)\n",
    "\n",
    "\n",
    "ax0.set_xlim([0, nbins])\n",
    "ax0.set_ylim([0, nbins])\n",
    "ax0.set_xticks(np.linspace(0, nbins, 6))\n",
    "ax0.set_yticks(np.linspace(0, nbins, 6))\n",
    "ax0.set_xticklabels(['{:.2f}'.format(label) for label in np.linspace(0, 0.1, 6)],\n",
    "                   rotation=60)\n",
    "ax0.set_yticklabels(['{:.2f}'.format(label) for label in np.linspace(0, 0.1, 6)])\n",
    "ax0.set_aspect('equal')\n",
    "ax1.set_xticks(np.linspace(0, nbins, 6))\n",
    "ax1.set_yticks(np.linspace(0, nbins, 6))\n",
    "ax1.set_xticklabels(['{:.2f}'.format(label) for label in np.linspace(0, 0.1, 6)],\n",
    "                   rotation=60)\n",
    "ax1.set_yticklabels([])\n",
    "ax2.set_xticks(np.linspace(0, nbins, 6))\n",
    "ax2.set_yticks(np.linspace(0, nbins, 6))\n",
    "ax2.set_xticklabels(['{:.2f}'.format(label) for label in np.linspace(0, 0.1, 6)], \n",
    "                    rotation=60)\n",
    "ax2.set_yticklabels([])\n",
    "\n",
    "selected = extract_bins_in_watershed(introgression_freq_filtered, bins, peaks)\n",
    "selected.sort_values(['chrom', 'start'], inplace=True)\n",
    "depleted_segments = find_significant_segments(selected, depleted=True, min_length=50000)\n",
    "enriched_segments = find_significant_segments(selected, enriched=True, min_length=50000)\n",
    "\n",
    "# introgression_freq_filtered.residuals += np.abs(introgression_freq_filtered.residuals.min())\n",
    "# introgression_freq_filtered.residuals /= introgression_freq_filtered.residuals.max()\n",
    "enriched_windows = BedTool.from_dataframe(introgression_freq_filtered).intersect(\n",
    "    BedTool.from_dataframe(enriched_segments), f=1).to_dataframe(names=introgression_freq_filtered.columns)\n",
    "depleted_windows = BedTool.from_dataframe(introgression_freq_filtered).intersect(\n",
    "    BedTool.from_dataframe(depleted_segments), f=1).to_dataframe(names=introgression_freq_filtered.columns)\n",
    "ax0.set_xlabel(\"Exp. introgression\\nfrequency (50 kb window)\")\n",
    "ax1.set_xlabel(\"Exp. introgression\\nfrequency (50 kb window)\")\n",
    "ax2.set_xlabel(\"Exp. introgression\\nfrequency (50 kb window)\")\n",
    "ax0.set_ylabel(\"Obs. introgression\\nfrequency (50 kb window)\")\n",
    "ax2.set_ylabel(\"Obs. introgression\\nfrequency (50 kb window)\")\n",
    "\n",
    "\n",
    "ax0.annotate(\"A\", (1, 1), (-0.3, 0.95), fontsize=14, fontweight='bold', xycoords='axes fraction')\n",
    "ax1.annotate(\"B\", (1, 1), (-0.15, 0.95), fontsize=14, fontweight='bold', xycoords='axes fraction')\n",
    "ax2.annotate(\"C\", (1, 1), (-0.2, 0.95), fontsize=14, fontweight='bold', xycoords='axes fraction')\n",
    "# get windows in watershed\n",
    "fig.savefig('visualizations/figure4.pdf', bbox_inches='tight', dpi=600)\n",
    "fig.savefig('visualizations/figure4.png', bbox_inches='tight', dpi=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = ((heatmap.T / introgression_freq_filtered.shape[0]) -\n",
    "             (heatmap_simulated.T / simulated_introgression_freq_filtered.shape[0]))\n",
    "\n",
    "residuals = ndimage.gaussian_filter(residuals, sigma=2, radius=6)\n",
    "residuals = np.where(residuals < 1e-6, 0, residuals)\n",
    "distance = ndimage.distance_transform_edt(residuals)\n",
    "coords = peak_local_max(distance, footprint=np.ones((6, 6)), threshold_abs=1e-6)\n",
    "mask = np.zeros(residuals.shape, dtype=bool)\n",
    "mask[tuple(coords.T)] = True\n",
    "markers, _ = ndimage.label(mask)\n",
    "labels = watershed(-distance, markers, mask=residuals)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(np.where((labels > 0) & (labels <= 3), 1, labels), cmap=plt.cm.nipy_spectral)\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = extract_bins_in_watershed(introgression_freq_filtered, bins, peaks)\n",
    "depleted_segments = find_significant_segments(selected.sort_values(['chrom', 'start']),\n",
    "                                              depleted=True, min_length=50000)\n",
    "enriched_segments = find_significant_segments(selected.sort_values(['chrom', 'start']), \n",
    "                                              enriched=True, min_length=50000)\n",
    "print(enriched_segments.iloc[:, :3])\n",
    "print(depleted_segments.iloc[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "BedTool.from_dataframe(depleted_segments).intersect(\n",
    "    BedTool.from_dataframe(gittleman_eur)).to_dataframe(names=enriched_segments.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "depleted_segments.chrom = [int(chrom.replace('chr', '')) for chrom in depleted_segments.chrom]\n",
    "enriched_segments.chrom = [int(chrom.replace('chr', '')) for chrom in enriched_segments.chrom]\n",
    "outlier_regions = pd.concat([depleted_segments.sort_values('chrom'), \n",
    "                             enriched_segments.sort_values('chrom')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gtf(file_path):\n",
    "    # Define column names as GTF does not have a header\n",
    "    column_names = [\n",
    "        'seqname', 'source', 'feature', 'start', 'end',\n",
    "        'score', 'strand', 'frame', 'attribute'\n",
    "    ]\n",
    "    \n",
    "    # Read the GTF file using pandas\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep='\\t',\n",
    "        comment='#',\n",
    "        names=column_names,\n",
    "        dtype={\n",
    "            'seqname': str, 'source': str, 'feature': str,\n",
    "            'start': int, 'end': int, 'score': str,\n",
    "            'strand': str, 'frame': str, 'attribute': str\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "gtf_file_path = 'data/reference/gencode.v46.annotation.gtf.gz'\n",
    "gtf_df = read_gtf(gtf_file_path)\n",
    "gtf_df['gene_type'] = [attribute.split('gene_type \"')[1].split('\";')[0] for attribute in gtf_df.attribute]\n",
    "gtf_df['gene_name'] = [attribute.split('gene_name \"')[1].split('\";')[0] for attribute in gtf_df.attribute]\n",
    "gtf_df['gene_id'] = [attribute.split('gene_id \"')[1].split('\";')[0] for attribute in gtf_df.attribute]\n",
    "\n",
    "gtf_df.drop('attribute', axis=1, inplace=True)\n",
    "gtf_df.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.legend_handler import HandlerTuple\n",
    "import string\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "gs_outer = fig.add_gridspec(95, 2, wspace=0.7)\n",
    "n_rows = 0\n",
    "introgression_freq = pd.read_csv('results50kb_wo_PEGS/ibdmix_Vindija33.19/ibdmix_results_masked_denisovan_combined_50kb_4.0LOD_afr_masked_coverage_per_individual_and_per_window50000_s_10000_expectations.bed',\n",
    "                                 sep='\\t', header=0)\n",
    "plt.subplots_adjust(hspace=(0.6))\n",
    "alphabet = string.ascii_uppercase\n",
    "for i, (chrom, start, end, \n",
    "        freq, expectation) in enumerate(outlier_regions.loc[:, ['chrom', 'start', 'end', \n",
    "                                                             'freq_updated', 'expectations']].values):\n",
    "    c_df = introgression_freq[(introgression_freq.chrom == f'chr{int(chrom)}') &\n",
    "                              (introgression_freq.start >= start - 500000) &\n",
    "                              (introgression_freq.end <= end + 500000)]\n",
    "    x_coords = (c_df.end + c_df.start).values / 2 / 1e6\n",
    "    expected = c_df.expectations.values / n_indv\n",
    "    observed = c_df.freq_updated.values / n_indv\n",
    "    genes = gtf_df[(gtf_df.seqname == f'chr{int(chrom)}') &\n",
    "                   ((gtf_df.end > start - 500000) &\n",
    "                   (gtf_df.start < end + 500000))]\n",
    "    genes = genes[genes.gene_type == 'protein_coding']\n",
    "    if i < 4:\n",
    "        gs = gridspec.GridSpecFromSubplotSpec(7 + genes.gene_name.unique().shape[0] * 2 + 1, 1, hspace=1.1,\n",
    "                                              subplot_spec = gs_outer[n_rows: n_rows + 7 +\n",
    "                                                                      genes.gene_name.unique().shape[0] * 2 \n",
    "                                                                      + 1, 0])\n",
    "    elif i == 4:\n",
    "        ax2.set_xlabel('Chromosome position (Mb, hg38 build)')\n",
    "        n_rows = 0\n",
    "        gs = gridspec.GridSpecFromSubplotSpec(7 + genes.gene_name.unique().shape[0] * 2 + 1, 1, hspace=1.1,\n",
    "                                                  subplot_spec = gs_outer[n_rows: n_rows + 7 +\n",
    "                                                                          genes.gene_name.unique().shape[0] \n",
    "                                                                          * 2 + 1, 1])\n",
    "    else:\n",
    "        gs = gridspec.GridSpecFromSubplotSpec(7 + genes.gene_name.unique().shape[0] * 2 + 1, 1, hspace=1.1,\n",
    "                                          subplot_spec = gs_outer[n_rows: n_rows + 7 +\n",
    "                                                                  genes.gene_name.unique().shape[0] \n",
    "                                                                  * 2 + 1, 1])\n",
    "    n_rows += 7 + genes.gene_name.unique().shape[0] * 2\n",
    "    ax = fig.add_subplot(gs[:5])\n",
    "#     ax1 = fig.add_subplot(gs[5:7])\n",
    "    \n",
    "    if freq > expectation:\n",
    "        color='blue'\n",
    "    else:\n",
    "        color='red'\n",
    "    if x_coords[0] > (start - 500000) / 1e6:\n",
    "        x_coords = np.concatenate([[(start - 500000) / 1e6], x_coords])\n",
    "        expected = np.concatenate([[0], expected])\n",
    "        ax2.set_yticks([])\n",
    "        observed = np.concatenate([[0], observed])\n",
    "    if x_coords[-1] < (end + 500000) / 1e6:\n",
    "        x_coords = np.concatenate([x_coords, [(end + 500000) / 1e6]])\n",
    "        expected = np.concatenate([expected, [0]])\n",
    "        observed = np.concatenate([observed, [0]])\n",
    "    \n",
    "    ax.annotate(alphabet[i], (1, 1), (-0.1, 1.2), fontsize=14, fontweight='bold', xycoords='axes fraction')\n",
    "    ax.plot(x_coords, observed, ls='-',\n",
    "               color='black', label='Observed')\n",
    "    ax.plot(x_coords, expected, ls='--',\n",
    "           color='grey', label=\"Expected\")\n",
    "#     ax1 = fig.add_subplot(gs[5: 7], sharex=ax)\n",
    "#     ax1.bar(start / 1e6, 1,\n",
    "#               width = (end - start) / 1e6, color=color, align='edge')\n",
    "    for i, gene in enumerate(genes.gene_name.unique()):    \n",
    "        ax2 = fig.add_subplot(gs[7 + i * 2 : 7 + i * 2 + 2])\n",
    "        gstart = genes.loc[(genes.gene_name == gene) &\n",
    "                            (genes.feature == 'gene'), 'start'].values[0]\n",
    "        gend = genes.loc[(genes.gene_name == gene) &\n",
    "                            (genes.feature == 'gene'), 'end'].values[0]\n",
    "        if gstart < start - 500000:\n",
    "            gstart = start - 500000\n",
    "        if gend > end + 500000:\n",
    "            gend = end + 500000\n",
    "        gstrand = genes.loc[(genes.gene_name == gene) &\n",
    "                            (genes.feature == 'gene'), 'strand'].values[0]\n",
    "        \n",
    "\n",
    "        for estart, eend, estrand in genes.loc[(genes.gene_name == gene) & \n",
    "                                               (genes.feature == 'exon'), ['start', 'end', 'strand']].values:\n",
    "            if estart < start - 500000:\n",
    "                estart = start - 500000\n",
    "            if eend > end + 500000:\n",
    "                eend = end + 500000\n",
    "#             if estart == gstart:\n",
    "#                 estart += 50000\n",
    "#             if end == gend + 500000:\n",
    "#                 eend -= 50000\n",
    "            if gstrand == '+':\n",
    "#                 ax2.annotate(\"\", xy=(estart / 1e6, 0), xytext=(eend / 1e6, 0), color='grey', \n",
    "#                          arrowprops=dict(arrowstyle=\"<-\"))\n",
    "                ax2.bar(estart / 1e6, height=0.4,\n",
    "                      width = (eend - estart) / 1e6, color='black',\n",
    "                      bottom=0.8, align='edge')\n",
    "            else:\n",
    "#                 ax2.annotate(\"\", xy=(estart / 1e6, 0), xytext=(eend / 1e6, 0), color='grey', \n",
    "#                          arrowprops=dict(arrowstyle=\"->\"))\n",
    "                ax2.bar(eend / 1e6, height=0.4,\n",
    "                      width = (estart - eend) / 1e6, color='black',\n",
    "                      bottom=0.8, align='edge')\n",
    "        if gstrand == '+':\n",
    "            ax2.annotate(\"\", xy=(gstart / 1e6, 1), xytext=(gend / 1e6 + 0.01, 1), color='grey', \n",
    "                         arrowprops=dict(arrowstyle=\"<-\", color='black'))\n",
    "        else:\n",
    "            ax2.annotate(\"\", xy=(gstart / 1e6 - 0.01, 1), xytext=(gend / 1e6, 1), color='grey', \n",
    "                         arrowprops=dict(arrowstyle=\"->\", color='black'))\n",
    "        ax2.annotate(gene, (1, 1), (1, 0.5), xycoords='axes fraction', fontsize=9, ha='left', va='center')\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.spines['left'].set_visible(False)\n",
    "        ax2.spines['bottom'].set_visible(False)\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_xticks([])\n",
    "        \n",
    "        ax2.set_xlim([(start - 500000)  / 1e6 , (end + 500000) / 1e6])    \n",
    "                \n",
    "    ax.set_xlim([(start - 500000)  / 1e6 , (end + 500000) / 1e6])    \n",
    "    ax.set_title(f'chr{int(chrom)}:{int(start):,}-{int(end):,}', fontsize=10,\n",
    "                 pad=10)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.yaxis.set_label_position(\"right\") \n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "    ax.set_xticks([])\n",
    "#     ax1.set_xlim([(start - 500000)  / 1e6 , (end + 500000) / 1e6])    \n",
    "#     ax1.spines['top'].set_visible(False)\n",
    "#     ax1.spines['right'].set_visible(False)\n",
    "#     ax1.spines['left'].set_visible(False)\n",
    "#     ax1.spines['bottom'].set_visible(False)\n",
    "#     ax1.set_yticks([])\n",
    "#     ax1.set_xticks([])\n",
    "    \n",
    "\n",
    "    ax2 = fig.add_subplot(gs[-1])\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.set_yticks([])\n",
    "    ax2.spines['left'].set_visible(False)\n",
    "    ax2.set_xlim([(start - 500000)  / 1e6 , (end + 500000) / 1e6])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xticks(np.arange((start - 500000) / 1e6, (end + 500000) /1e6, 200000 / 1e6))\n",
    "    ax2.set_xticklabels(['{:.1f}'.format(label) for label in ax2.get_xticks()], rotation=45, fontsize=9)\n",
    "    if i < 4:\n",
    "        n_rows += 13\n",
    "    else:\n",
    "        n_rows += 17\n",
    "ax2.set_xlabel('Chromosome position (Mb, hg38 build)')\n",
    "handles = [Line2D([0], [0], ls='--', color='grey'),\n",
    "           Line2D([0], [0], ls='-', color='black')]\n",
    "ax2.legend(handles, ['Expected introgression frequency',\n",
    "                     'Observed introgression frequency'], \n",
    "           bbox_to_anchor=(-0.4, -26), loc='center', ncol=2,  markerscale=2,\n",
    "           handletextpad=0.4, columnspacing=1, handlelength=1.5, \n",
    "           handler_map={tuple: HandlerTuple(ndivide=None)})\n",
    "\n",
    "ax = fig.add_subplot(gs_outer[n_rows:])\n",
    "ax.remove()\n",
    "#     ax2.spines['bottom'].set_visible(True)\n",
    "    \n",
    "# #     ax[i].set_xticks((c_df.end + c_df.start)[::10] / 2 / 1e6)\n",
    "# #     ax[i].set_xticklabels((c_df.end + c_df.start)[::10] / 2 / 1e6)\n",
    "# ax[i].set_xlabel('Chromosomal position (Mb)')\n",
    "# ax[i].legend(bbox_to_anchor=(0.5, -.5), loc='upper center', ncol=2)\n",
    "fig.savefig('visualizations/figure5.pdf', bbox_inches='tight', dpi=600)\n",
    "fig.savefig('visualizations/figure5.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### Introgression landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle, Patch\n",
    "\n",
    "deserts = pd.read_csv('results50kb_wo_PEGS/ibdmix_Vindija33.19/AMR_novel_introgression_deserts.bed', sep='\\t',\n",
    "                      names=['chrom', 'start', 'end'])\n",
    "deserts_eur = pd.read_csv('data/known_introgression_deserts_hg38.bed', sep='\\t', \n",
    "                          names=['chrom', 'start', 'end', 'reference','fragment'])\n",
    "deserts = BedTool.from_dataframe(deserts).intersect(BedTool.from_dataframe(deserts_eur), \n",
    "                                                    v=True).to_dataframe()\n",
    "deserts_eur = BedTool.from_dataframe(deserts_eur).merge().to_dataframe()\n",
    "\n",
    "# merged_introgression_freq = BedTool.from_dataframe(introgression_freq).merge(c=[4, 6, 7], o='mean').to_dataframe()\n",
    "# merged_introgression_freq = merged_introgression_freq.rename(columns={'name': 'AMR_freq', 'score': 'EUR_freq',\n",
    "#                                                                      'strand': \"EAS_freq\"})\n",
    "# introgression_freq.chrom = [int(chrom.replace('chr', '')) for chrom in introgression_freq.chrom]\n",
    "chromosome_arms = pd.read_csv('data/reference/hg38_chromosome_arms.bed', sep='\\t',\n",
    "                              names=['chrom', 'start', 'end', 'arm'])\n",
    "max_chrom_size = chromosome_arms.end.max() / 1e6\n",
    "chromosome_arms = chromosome_arms[chromosome_arms.arm == 'p']\n",
    "fig, ax = plt.subplots(22, 1, figsize=(6, 9), sharex=True)\n",
    "max_freq = 1\n",
    "for chrom in tqdm(range(1, 23)):\n",
    "    desert_patches = []\n",
    "    known_deserts_patches = []\n",
    "        \n",
    "    ax[chrom - 1] = plot_haplotype_frequencies(ibdmix_masked[ibdmix_masked.super_pop == 'AMR'].drop_duplicates(['chrom', 'start', 'end']),\n",
    "                                               'freq_updated', f'chr{chrom}', ax[chrom - 1], 1, \n",
    "                                               'darkmagenta')\n",
    "    if deserts[deserts.chrom == f'chr{chrom}'].shape[0] > 0:\n",
    "        for start, end in deserts.loc[deserts.chrom == f'chr{chrom}', ['start', 'end']].values:\n",
    "            desert_patches.append(Rectangle((start / 1e6, 0.0), (end - start) / 1e6, max_freq))\n",
    "            \n",
    "        pc = PatchCollection(desert_patches, edgecolor='red', facecolor='red', alpha=0.2)\n",
    "        ax[chrom - 1].add_collection(pc)\n",
    "    if deserts_eur[deserts_eur.chrom == f'chr{chrom}'].shape[0] > 0:\n",
    "        for start, end in deserts_eur.loc[deserts_eur.chrom == f'chr{chrom}', ['start', 'end']].values:\n",
    "            known_deserts_patches.append(Rectangle((start / 1e6, 0.0), (end - start) / 1e6, max_freq))\n",
    "            \n",
    "        pc = PatchCollection(known_deserts_patches, edgecolor='orange', facecolor='orange', \n",
    "                             alpha=0.2)\n",
    "        ax[chrom - 1].add_collection(pc)\n",
    "    ax[chrom - 1].scatter(chromosome_arms.loc[chromosome_arms.chrom == chrom, 'end'].values[0] / 1e6, \n",
    "                          max_freq / 2, s=15, c='black')\n",
    "    ax[chrom - 1].set_yticks([max_freq / 2])\n",
    "    ax[chrom - 1].set_yticklabels([chrom])\n",
    "    ax[chrom - 1].set_ylim([-0.05, max_freq])\n",
    "    for spine in ax[chrom-1].spines.values():\n",
    "        spine.set_visible(False)\n",
    "    if chrom != 22:\n",
    "        ax[chrom - 1].tick_params(axis='both', bottom=False, left=False)\n",
    "    else:\n",
    "        ax[chrom - 1].tick_params(axis='both', bottom=True, left=False)\n",
    "ax[chrom - 1].set_xlim([0, max_chrom_size])\n",
    "# ax[chrom - 1].set_xlabel('Chromosome position (Mb, hg38 build)')\n",
    "legend = [Patch(facecolor='darkmagenta', edgecolor='darkmagenta', alpha=0.3, \n",
    "                label='Neanderthal segments'),\n",
    "#           Line2D([0], [0], ls='-', color='lightblue', alpha=.2, label=\"Introgression freq. EUR\"),\n",
    "#           Line2D([0], [0], ls='-', color='blue', alpha=.1, label=\"Introgression freq. EAS\"),\n",
    "          Patch(facecolor='red', edgecolor='red', alpha=0.3, \n",
    "                label='Novel introgression desert-like region'),\n",
    "          Patch(facecolor='orange', edgecolor='orange', alpha=0.3, \n",
    "                label='Vernot et al. 2016 + Chen et al. 2020')]\n",
    "ax[chrom - 1].legend(handles=legend, ncol=1, bbox_to_anchor=(0.5, -1.9),\n",
    "                     loc='upper center', fontsize='medium')\n",
    "ax[0].annotate(\"A\", (1, 1), (-0.15, 0.3), fontsize=16, fontweight='bold', xycoords='axes fraction')\n",
    "fig.supylabel('Chromosomes', x=0.04, fontsize=11)\n",
    "fig.supxlabel('Chromosome position (Mb, hg38 build)', y=0.06, fontsize=11)\n",
    "fig.savefig(\"visualizations/introgression_landscape.pdf\", bbox_inches='tight', dpi=600)\n",
    "fig.savefig(\"visualizations/introgression_landscape.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "### Plot statistics for introgression deserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_introgressed = []\n",
    "df_ils = []\n",
    "df_non_introgressed = []\n",
    "dfs = []\n",
    "# chromosomes = np.arange(1, 23)\n",
    "for chrom in tqdm.tqdm(chromosomes):\n",
    "    df = pd.read_csv(f'../ancestral_recombination_graphs/chr{chrom}_tmrca_summarized_hg38.tab', sep='\\t', \n",
    "                     header=0)\n",
    "    df.dropna(inplace=True)\n",
    "    columns = df.columns.values.tolist()\n",
    "    columns.insert(2, 'end')\n",
    "    df['end'] = df.POS + 1\n",
    "    df = df.loc[:, columns]\n",
    "    dfs.append(df)\n",
    "    # derived allele found in present-day Europeans but not in Africans\n",
    "    and in at least one Neanderthal but Denisovan\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df = BedTool.from_dataframe(df).intersect('data/masks/cpg.bed', v=True).to_dataframe(names=df.columns)\n",
    "\n",
    "df_introgressed = df[(df.AFR_1KGP == 0) & (df.EUR_1KGP > 0) &\n",
    "                     ((df.Nea_Altai > 0) | (df['Nea_Vindija33.19'] > 0) | (df.Nea_Chagyrskaya > 0)) & \n",
    "                     (df.Denisova == 0)]\n",
    "# derived allele found in present-day Europeans but not in Africans\n",
    "# and in at least one Neanderthal and Denisovan --> likely ILS\n",
    "df_ils = df[(df.AFR_1KGP == 0) & (df.EUR_1KGP == 0) &\n",
    "            ((df.Nea_Altai > 0) | (df['Nea_Vindija33.19'] > 0) | (df.Nea_Chagyrskaya > 0)) & \n",
    "            (df.Denisova > 0)]\n",
    "df_non_introgressed = df[(df.AFR_1KGP == 0) & (df.EUR_1KGP > 0) & \n",
    "                         (df.Nea_Altai == 0) & (df['Nea_Vindija33.19'] == 0) & \n",
    "                         (df.Nea_Chagyrskaya == 0) & (df.Denisova == 0)]\n",
    "\n",
    "desert_vals = []\n",
    "for chrom, start, end in deserts.loc[:, ['chrom', 'start', 'end']].values:\n",
    "    desert_vals.append(df_introgressed.loc[(df_introgressed.CHROM == chrom) & \n",
    "                                           (df_introgressed.POS >= start) & \n",
    "                                           (df_introgressed.POS < end), 'TMRCA_kya'].values)\n",
    "desert_vals = np.concatenate(desert_vals)\n",
    "\n",
    "desert_eur_vals = []\n",
    "for chrom, start, end in deserts_eur.loc[:, ['chrom', 'start', 'end']].values:\n",
    "    desert_eur_vals.append(df_introgressed.loc[(df_introgressed.CHROM == chrom) & \n",
    "                                               (df_introgressed.POS >= start) & \n",
    "                                               (df_introgressed.POS < end), 'TMRCA_kya'].values)\n",
    "desert_eur_vals = np.concatenate(desert_eur_vals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def get_centralities(node_centralities, targets):\n",
    "    centralities = []\n",
    "    for prot in set(targets):\n",
    "        try:\n",
    "            centralities.append(node_centralities[prot])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return centralities\n",
    "\n",
    "def plot_centrality_helper(centralities, color, label, ax):\n",
    "    ax.step(np.sort(centralities), \n",
    "            np.arange(1, len(centralities) + 1) / float(len(centralities)), \n",
    "            color=color, label=label)\n",
    "    return ax\n",
    "\n",
    "G_400 = nx.read_edgelist('data/reference/9606.protein.links.v11.5.score_g_400.txt', data=((\"weight\", float),))\n",
    "G_700 = nx.read_edgelist('data/reference/9606.protein.links.v11.5.score_g_700.txt', data=((\"weight\", float),))\n",
    "deserts_all = pd.read_csv('results50kb_wo_PEGS/ibdmix_Vindija33.19/AMR_foreground_list_of_genes_in_deserts_converted.txt',\n",
    "                      sep='\\t', header=0)\n",
    "ensembl_df = pd.read_csv('data/reference/Homo_sapiens.GRCh38.109.uniprot.tsv', sep='\\t', header=0)\n",
    "deserts_eur = pd.read_csv('results50kb_wo_PEGS/foreground_list_of_genes_in_known_deserts_converted.txt',\n",
    "                      sep='\\t', header=0)\n",
    "bg_protein = ensembl_df.protein_stable_id.unique()\n",
    "fg_deserts = ensembl_df.loc[np.isin(ensembl_df.transcript_stable_id.values, deserts_all.ensembl_transcript_id.values), 'protein_stable_id']\n",
    "fg_deserts_eur = ensembl_df.loc[np.isin(ensembl_df.transcript_stable_id.values, deserts_eur.ensembl_transcript_id.values), 'protein_stable_id']\n",
    "\n",
    "all_proteins = []\n",
    "nodes = G_400.nodes()\n",
    "for prot in set(bg_protein):\n",
    "    if prot in nodes:\n",
    "        all_proteins.append(prot)\n",
    "for prot in set(fg_deserts):\n",
    "    if prot in nodes:\n",
    "        all_proteins.append(prot)\n",
    "all_proteins = list(set(all_proteins))\n",
    "degrees_400 = nx.degree(G_400)\n",
    "degrees_700 = nx.degree(G_700)\n",
    "\n",
    "random_degrees_400 = get_centralities(degrees_400, np.random.choice(list(G_400.nodes), \n",
    "                                                            len(all_proteins)))\n",
    "random_degrees_400 = np.array(random_degrees_400)\n",
    "\n",
    "random_degrees_700 = get_centralities(degrees_700, np.random.choice(list(G_700.nodes), \n",
    "                                                            len(all_proteins)))\n",
    "random_degrees_700 = np.array(random_degrees_700)\n",
    "\n",
    "# bg_degrees = get_centralities(degrees, bg_protein)\n",
    "desert_degrees_400 = get_centralities(degrees_400, fg_deserts)\n",
    "desert_eur_degrees_400 = get_centralities(degrees_400, fg_deserts_eur)\n",
    "desert_degrees_700 = get_centralities(degrees_700, fg_deserts)\n",
    "desert_eur_degrees_700 = get_centralities(degrees_700, fg_deserts_eur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 9))\n",
    "\n",
    "gs = fig.add_gridspec(7, 2, height_ratios=[10, 2, 10, 2, 10, 1, 1], wspace=0.55)\n",
    "ax0 = fig.add_subplot(gs[0, 1])\n",
    "ax1 = fig.add_subplot(gs[2, 0])\n",
    "ax2 = fig.add_subplot(gs[2, 1], sharey=ax1)\n",
    "ax3 = fig.add_subplot(gs[4, 0])\n",
    "ax4 = fig.add_subplot(gs[4, 1], sharey=ax3)\n",
    "ax5 = fig.add_subplot(gs[6, 0])\n",
    "\n",
    "\n",
    "deserts = pd.read_csv('results50kb_wo_PEGS/ibdmix_Vindija33.19/AMR_novel_introgression_deserts.bed', sep='\\t',\n",
    "                      names=['chrom', 'start', 'end'])\n",
    "deserts_eur = pd.read_csv('data/known_introgression_deserts_hg38.bed', sep='\\t', \n",
    "                          names=['chrom', 'start', 'end', 'reference','fragment'])\n",
    "deserts = BedTool.from_dataframe(deserts).intersect(BedTool.from_dataframe(deserts_eur), \n",
    "                                                    v=True).to_dataframe()\n",
    "deserts_eur = BedTool.from_dataframe(deserts_eur).merge().to_dataframe()\n",
    "bstatistic = pd.read_csv('data/reference/bstat_hg38.bed.gz', sep='\\t', \n",
    "                         names=['chrom_r', 'start_r', 'end_r', \"B\"])\n",
    "columns = ['chrom', 'start', 'end', 'chrom_r', 'start_r', 'end_r', \"B\", 'overlap']\n",
    "deserts_b = BedTool.from_dataframe(deserts).intersect(\n",
    "    BedTool.from_dataframe(bstatistic), wao=True).to_dataframe(names=columns)\n",
    "deserts_eur_b = BedTool.from_dataframe(deserts_eur).intersect(\n",
    "    BedTool.from_dataframe(bstatistic), wao=True).to_dataframe(names=columns)\n",
    "\n",
    "ax0.step(np.sort(bstatistic.B.values)  / 1000, \n",
    "        np.cumsum((bstatistic.end_r.values - bstatistic.start_r.values)[np.argsort(bstatistic.B.values)] / \n",
    "        (bstatistic.end_r - bstatistic.start_r).sum()), ls='--', color='black', label='Genome-wide background' )\n",
    "ax0.step(np.sort(deserts_b.B.values) / 1000, np.cumsum(deserts_b.overlap.values[np.argsort(deserts_b.B.values)] / \n",
    "                                             deserts_b.overlap.sum()), \n",
    "        ls='-', color='red', label='Novel desert-like regions')\n",
    "ax0.step(np.sort(deserts_eur_b.B.values) / 1000, \n",
    "        np.cumsum(deserts_eur_b.overlap.values[np.argsort(deserts_eur_b.B.values)] / \n",
    "                  deserts_eur_b.overlap.sum()), \n",
    "        ls='-', color='orange', label='Known deserts')\n",
    "ax0.set_xlabel(\"B-statistic\")\n",
    "ax0.set_ylabel('ECDF')\n",
    "ax0.annotate(\"B\", (1, 1), (-0.4, 0.9), fontsize=16, fontweight='bold', xycoords='axes fraction')\n",
    "\n",
    "\n",
    "\n",
    "ax1.step(np.sort(df_introgressed.TMRCA_kya.values),\n",
    "        np.cumsum(np.repeat(1 / df_introgressed.shape[0], df_introgressed.shape[0])), ls='--', color='black',\n",
    "        label='Genome-wide background')\n",
    "ax1.step(np.sort(desert_vals),\n",
    "        np.cumsum(np.repeat(1 / len(desert_vals), len(desert_vals))), ls='-', color='red', \n",
    "        label='Novel desert-like regions')\n",
    "ax1.step(np.sort(desert_eur_vals),\n",
    "        np.cumsum(np.repeat(1 / len(desert_eur_vals), len(desert_eur_vals))), ls='-', color='orange', \n",
    "        label='Known deserts')\n",
    "# ax.legend(bbox_to_anchor=(0.5, -.14), loc='upper center', ncol=3)\n",
    "ax1.set_xlabel(\"TMRCA in kya\")\n",
    "ax1.set_ylabel('ECDF')\n",
    "ax1.set_xlim([0, 1000])\n",
    "ax1.annotate(\"C\", (1, 1), (-0.4, 0.9), fontsize=16, fontweight='bold', xycoords='axes fraction')\n",
    "\n",
    "\n",
    "deserts = pd.read_csv('results50kb_wo_PEGS/ibdmix_Vindija33.19/AMR_novel_introgression_deserts.bed', sep='\\t',\n",
    "                      names=['chrom', 'start', 'end'])\n",
    "deserts_eur = pd.read_csv('data/known_introgression_deserts_hg38.bed', sep='\\t', \n",
    "                          names=['chrom', 'start', 'end', 'reference','fragment'])\n",
    "deserts = BedTool.from_dataframe(deserts).intersect(BedTool.from_dataframe(deserts_eur), \n",
    "                                                    v=True).to_dataframe()\n",
    "deserts_eur = BedTool.from_dataframe(deserts_eur).merge().to_dataframe()\n",
    "phastcons = pd.read_csv('data/reference/phastCons100way.bed.gz', sep='\\t', \n",
    "                         names=['chrom_r', 'start_r', 'end_r', \"lowerLimit\", \"upperLimit\",  \"phastCons\"])\n",
    "columns = ['chrom', 'start', 'end', 'chrom_r', 'start_r', 'end_r', \"lowerLimit\", \n",
    "           \"upperLimit\",  \"phastCons\", 'overlap']\n",
    "deserts_pc = BedTool.from_dataframe(deserts).intersect(\n",
    "    BedTool.from_dataframe(phastcons), wao=True).to_dataframe(names=columns)\n",
    "deserts_eur_pc = BedTool.from_dataframe(deserts_eur).intersect(\n",
    "    BedTool.from_dataframe(phastcons), wao=True).to_dataframe(names=columns)\n",
    "\n",
    "\n",
    "ax2 = plot_centrality_helper(random_degrees_400, 'black', 'Genome-wide background', ax2)\n",
    "# ax = plot_centrality_helper(random_degrees[random_degrees > 1], 'grey', 'Genome-wide background (Node degree > 1)', ax)\n",
    "ax2 = plot_centrality_helper(desert_degrees_400, 'red', 'Novel desert-like regions', ax2)\n",
    "ax2 = plot_centrality_helper(desert_eur_degrees_400, 'orange', 'Known deserts', ax2)\n",
    "\n",
    "\n",
    "ax3 = plot_centrality_helper(random_degrees_700, 'black', 'Genome-wide background', ax3)\n",
    "# ax = plot_centrality_helper(random_degrees[random_degrees > 1], 'grey', 'Genome-wide background (Node degree > 1)', ax)\n",
    "ax3 = plot_centrality_helper(desert_degrees_700, 'red', 'Novel desert-like regions', ax3)\n",
    "ax3 = plot_centrality_helper(desert_eur_degrees_700, 'orange', 'Known deserts', ax3)\n",
    "\n",
    "ax2.set_xlim([0, 500])\n",
    "ax2.set_ylim([0, 1.05])\n",
    "ax3.set_xlim([0, 250])\n",
    "ax3.set_ylim([0, 1.05])\n",
    "\n",
    "ax2.set_xlabel('Node degree in PPI (score >400)')\n",
    "ax3.set_xlabel('Node degree in PPI (score >700)', labelpad=8)\n",
    "ax3.set_ylabel('ECDF')\n",
    "ax2.annotate(\"D\", (1, 1), (-0.4, 0.9), fontsize=16, fontweight='bold', xycoords='axes fraction')\n",
    "ax3.annotate(\"E\", (1, 1), (-0.4, 0.9), fontsize=16, fontweight='bold', xycoords='axes fraction')\n",
    "\n",
    "\n",
    "\n",
    "ax4.step(np.sort(phastcons.phastCons.values), \n",
    "        np.cumsum((phastcons.end_r.values - phastcons.start_r.values)[np.argsort(phastcons.phastCons.values)] / \n",
    "        (phastcons.end_r - phastcons.start_r).sum()), ls='--', color='black', \n",
    "           label='Genome-wide background' )\n",
    "ax4.step(np.sort(deserts_pc.phastCons.values), \n",
    "           np.cumsum(deserts_pc.overlap.values[np.argsort(deserts_pc.phastCons.values)] / \n",
    "                     deserts_pc.overlap.sum()), \n",
    "        ls='-', color='red', label='Novel desert-like regions')\n",
    "ax4.step(np.sort(deserts_eur_pc.phastCons.values), \n",
    "        np.cumsum(deserts_eur_pc.overlap.values[np.argsort(deserts_eur_pc.phastCons.values)] / \n",
    "                  deserts_eur_pc.overlap.sum()), \n",
    "        ls='-', color='orange', label='Known deserts')\n",
    "ax4.set_xlabel(\"phastCons score\")\n",
    "ax4.set_xscale('log')\n",
    "ax4.set_xlim([.001, 1])\n",
    "\n",
    "ax4.annotate(\"F\", (1, 1), (-0.4, 0.9), fontsize=16, fontweight='bold', xycoords='axes fraction')\n",
    "\n",
    "\n",
    "handles = [Line2D([0] , [0], color='black', ls='--', label='Genomic background'),\n",
    "           Line2D([0] , [0], color='orange', ls='--', label='Novel desert-like regions'),\n",
    "           Line2D([0] , [0], color='red', ls='--', label='Known deserts')]\n",
    "ax5.spines['top'].set_visible(False)\n",
    "ax5.spines['right'].set_visible(False)\n",
    "ax5.spines['left'].set_visible(False)\n",
    "ax5.spines['bottom'].set_visible(False)\n",
    "ax5.set_xticks([])\n",
    "ax5.set_yticks([])\n",
    "ax5.legend(handles=handles, bbox_to_anchor=(1.2, 1),loc='upper center', ncol=2, handlelength=1, \n",
    "             handletextpad=0.4, labelspacing=0.3, columnspacing=1)\n",
    "\n",
    "\n",
    "fig.savefig('visualizations/desert_like_regions_stats.pdf', bbox_inches='tight', dpi=600)\n",
    "fig.savefig('visualizations/desert_like_regions_stats.png', bbox_inches='tight', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "deserts = pd.read_csv('results50kb_wo_PEGS/ibdmix_Vindija33.19/AMR_novel_introgression_deserts.bed', sep='\\t',\n",
    "                      names=['chrom', 'start', 'end'])\n",
    "deserts_eur = pd.read_csv('data/known_introgression_deserts_hg38.bed', sep='\\t', \n",
    "                          names=['chrom', 'start', 'end', 'reference','fragment'])\n",
    "deserts = BedTool.from_dataframe(deserts).intersect(BedTool.from_dataframe(deserts_eur), \n",
    "                                                    v=True).to_dataframe()\n",
    "deserts_eur = BedTool.from_dataframe(deserts_eur).merge().to_dataframe()\n",
    "bstatistic = pd.read_csv('data/reference/bstat_hg38.bed.gz', sep='\\t', \n",
    "                         names=['chrom_r', 'start_r', 'end_r', \"B\"])\n",
    "columns = ['chrom', 'start', 'end', 'chrom_r', 'start_r', 'end_r', \"B\", 'overlap']\n",
    "deserts_b = BedTool.from_dataframe(deserts).intersect(\n",
    "    BedTool.from_dataframe(bstatistic), wao=True).to_dataframe(names=columns)\n",
    "deserts_eur_b = BedTool.from_dataframe(deserts_eur).intersect(\n",
    "    BedTool.from_dataframe(bstatistic), wao=True).to_dataframe(names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitneyu(deserts_eur_b.B * deserts_eur_b.overlap / deserts_eur_b.overlap.sum(), \n",
    "             bstatistic.B * (bstatistic.end_r - bstatistic.start_r) / (bstatistic.end_r - bstatistic.start_r).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitneyu(deserts_eur_b.B * deserts_eur_b.overlap / deserts_eur_b.overlap.sum(), \n",
    "             deserts_b.B * deserts_b.overlap / deserts_b.overlap.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "deserts = pd.read_csv('results50kb_wo_PEGS/ibdmix_Vindija33.19/AMR_novel_introgression_deserts.bed', sep='\\t',\n",
    "                      names=['chrom', 'start', 'end'])\n",
    "deserts_eur = pd.read_csv('data/known_introgression_deserts_hg38.bed', sep='\\t', \n",
    "                          names=['chrom', 'start', 'end', 'reference','fragment'])\n",
    "deserts = BedTool.from_dataframe(deserts).intersect(BedTool.from_dataframe(deserts_eur), \n",
    "                                                    v=True).to_dataframe()\n",
    "deserts_eur = BedTool.from_dataframe(deserts_eur).merge().to_dataframe()\n",
    "phastcons = pd.read_csv('data/reference/phastCons100way.bed.gz', sep='\\t', \n",
    "                         names=['chrom_r', 'start_r', 'end_r', \"lowerLimit\", \"upperLimit\",  \"phastCons\"])\n",
    "columns = ['chrom', 'start', 'end', 'chrom_r', 'start_r', 'end_r', \"lowerLimit\", \n",
    "           \"upperLimit\",  \"phastCons\", 'overlap']\n",
    "deserts_pc = BedTool.from_dataframe(deserts).intersect(\n",
    "    BedTool.from_dataframe(phastcons), wao=True).to_dataframe(names=columns)\n",
    "deserts_eur_pc = BedTool.from_dataframe(deserts_eur).intersect(\n",
    "    BedTool.from_dataframe(phastcons), wao=True).to_dataframe(names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitneyu(deserts_pc.phastCons * deserts_pc.overlap / deserts_pc.overlap.sum(), \n",
    "             phastcons.phastCons * (phastcons.end_r - phastcons.start_r) / (phastcons.end_r - phastcons.start_r).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniforge3-snakemake]",
   "language": "python",
   "name": "conda-env-miniforge3-snakemake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
